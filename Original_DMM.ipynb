{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from os.path import exists\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import TransformedDistribution\n",
    "from pyro.distributions.transforms import affine_autoregressive\n",
    "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceEnum_ELBO, TraceTMC_ELBO, config_enumerate\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "import pretty_midi\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import wave\n",
    "from scipy.io.wavfile import write\n",
    "# import fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## args\n",
    "num_epochs=5000\n",
    "learning_rate=0.003\n",
    "rpt_eps = 1e-20\n",
    "rnn_clamp = 1.\n",
    "# learning_rate=0.0003\n",
    "beta1=0.96\n",
    "beta2=0.999\n",
    "clip_norm=10.0\n",
    "lr_decay=0.99996\n",
    "mini_batch_size=20\n",
    "annealing_epochs=1000\n",
    "minimum_annealing_factor=0.2\n",
    "rnn_dropout_rate=0.1\n",
    "num_iafs=0\n",
    "iaf_dim=100\n",
    "checkpoint_freq=100\n",
    "load_opt=''\n",
    "load_model=''\n",
    "save_opt=''\n",
    "save_model=''\n",
    "cuda=False\n",
    "jit=False\n",
    "tmc=False\n",
    "tmcelbo=False\n",
    "rpt = True\n",
    "tmc_num_samples=10\n",
    "log='dmm.log'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 長さ最長129、例えば長さが60のやつは61~129はすべて0データ\n",
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "training_seq_lengths = data['train']['sequence_lengths']\n",
    "training_data_sequences = data['train']['sequences']\n",
    "\n",
    "## super easy training set\n",
    "# training_seq_lengths = torch.tensor([8])\n",
    "# training_data_sequences = torch.zeros(10,8,88)\n",
    "# for i in range(5):\n",
    "#     for j in range(8):\n",
    "#         training_data_sequences[i][j][int(20+i*10)] = 1\n",
    "# for i in range(5,8):\n",
    "#     training_data_sequences[i][0][int(110-i*10)  ] = 1\n",
    "#     training_data_sequences[i][1][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][2][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][3][int(110-i*10)+1] = 1\n",
    "#     training_data_sequences[i][4][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][5][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][6][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][7][int(110-i*10)+1] = 1\n",
    "\n",
    "test_seq_lengths = data['test']['sequence_lengths']\n",
    "test_data_sequences = data['test']['sequences']\n",
    "val_seq_lengths = data['valid']['sequence_lengths']\n",
    "val_data_sequences = data['valid']['sequences']\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = float(torch.sum(training_seq_lengths))\n",
    "N_mini_batches = int(N_train_data / mini_batch_size +\n",
    "                    int(N_train_data % mini_batch_size > 0))\n",
    "\n",
    "\n",
    "# how often we do validation/test evaluation during training\n",
    "val_test_frequency = 50\n",
    "# the number of samples we use to do the evaluation\n",
    "n_eval_samples = 1\n",
    "\n",
    "# rep is short for \"repeat\"\n",
    "# which means how many times we use certain sample to do validation/test evaluation during training\n",
    "def rep(x):\n",
    "        rep_shape = torch.Size([x.size(0) * n_eval_samples]) + x.size()[1:]\n",
    "        repeat_dims = [1] * len(x.size())\n",
    "        repeat_dims[0] = n_eval_samples\n",
    "        return x.repeat(repeat_dims).reshape(n_eval_samples, -1).transpose(1, 0).reshape(rep_shape)\n",
    "\n",
    "# get the validation/test data ready for the dmm: pack into sequences, etc.\n",
    "val_seq_lengths = rep(val_seq_lengths)\n",
    "test_seq_lengths = rep(test_seq_lengths)\n",
    "val_batch, val_batch_reversed, val_batch_mask, val_seq_lengths = poly.get_mini_batch(\n",
    "    torch.arange(n_eval_samples * val_data_sequences.shape[0]), rep(val_data_sequences),\n",
    "    val_seq_lengths, cuda=cuda)\n",
    "test_batch, test_batch_reversed, test_batch_mask, test_seq_lengths = poly.get_mini_batch(\n",
    "    torch.arange(n_eval_samples * test_data_sequences.shape[0]), rep(test_data_sequences),\n",
    "    test_seq_lengths, cuda=cuda)"
   ]
  },
  {
   "source": [
    "# Emitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the bernoulli observation likelihood `p(x_t | z_t)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim)\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim)\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z_t):\n",
    "        \"\"\"\n",
    "        Given the latent z at a particular time step t we return the vector of\n",
    "        probabilities `ps` that parameterizes the bernoulli distribution `p(x_t|z_t)`\n",
    "        \"\"\"\n",
    "        h1 = self.relu(self.lin_z_to_hidden(z_t))\n",
    "        h2 = self.relu(self.lin_hidden_to_hidden(h1))\n",
    "        ps = torch.sigmoid(self.lin_hidden_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "source": [
    "# Transmitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the gaussian latent transition probability `p(z_t | z_{t-1})`\n",
    "    See section 5 in the reference for comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # initialize the six linear transformations used in the neural network\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim)\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        # modify the default initialization of lin_z_to_loc\n",
    "        # so that it's starts out as the identity function\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        # initialize the three non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1):\n",
    "        \"\"\"\n",
    "        Given the latent `z_{t-1}` corresponding to the time step t-1\n",
    "        we return the mean and scale vectors that parameterize the\n",
    "        (diagonal) gaussian distribution `p(z_t | z_{t-1})`\n",
    "        \"\"\"\n",
    "        # compute the gating function\n",
    "        _gate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\n",
    "        gate = torch.sigmoid(self.lin_gate_hidden_to_z(_gate))\n",
    "        # compute the 'proposed mean'\n",
    "        _proposed_mean = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\n",
    "        # assemble the actual mean used to sample z_t, which mixes a linear transformation\n",
    "        # of z_{t-1} with the proposed mean modulated by the gating function\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\n",
    "        # compute the scale used to sample z_t, using the proposed mean from\n",
    "        # above as input the softplus ensures that scale is positive\n",
    "        scale = self.softplus(self.lin_sig(self.relu(proposed_mean)))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale\n"
   ]
  },
  {
   "source": [
    "# Combiner"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes `q(z_t | z_{t-1}, x_{t:T})`, which is the basic building block\n",
    "    of the guide (i.e. the variational distribution). The dependence on `x_{t:T}` is\n",
    "    through the hidden state of the RNN (see the PyTorch module `rnn` below)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        \"\"\"\n",
    "        Given the latent z at at a particular time step t-1 as well as the hidden\n",
    "        state of the RNN `h(x_{t:T})` we return the mean and scale vectors that\n",
    "        parameterize the (diagonal) gaussian distribution `q(z_t | z_{t-1}, x_{t:T})`\n",
    "        \"\"\"\n",
    "        # combine the rnn hidden state with a transformed version of z_t_1\n",
    "        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        # use the combined hidden state to compute the mean used to sample z_t\n",
    "        loc = self.lin_hidden_to_loc(h_combined)\n",
    "        # use the combined hidden state to compute the scale used to sample z_t\n",
    "        scale = self.softplus(self.lin_hidden_to_scale(h_combined))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale\n"
   ]
  },
  {
   "source": [
    "# Deep Markov Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    This PyTorch Module encapsulates the model as well as the\n",
    "    variational distribution (the guide) for the Deep Markov Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=88, z_dim=100, emission_dim=100,\n",
    "                 transition_dim=200, rnn_dim=600, num_layers=1, rnn_dropout_rate=0.1,\n",
    "                 num_iafs=0, iaf_dim=50, use_cuda=False, rnn_check=False, rpt=True):\n",
    "        super().__init__()\n",
    "        # instantiate PyTorch modules used in the model and guide below\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        # dropout just takes effect on inner layers of rnn\n",
    "        rnn_dropout_rate = 0. if num_layers == 1 else rnn_dropout_rate\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=rnn_dim, nonlinearity='relu',\n",
    "                          batch_first=True, bidirectional=False, num_layers=num_layers,\n",
    "                          dropout=rnn_dropout_rate)\n",
    "\n",
    "        # if we're using normalizing flows, instantiate those too\n",
    "        self.iafs = [affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)]\n",
    "        self.iafs_modules = nn.ModuleList(self.iafs)\n",
    "\n",
    "        # define a (trainable) parameters z_0 and z_q_0 that help define the probability\n",
    "        # distributions p(z_1) and q(z_1)\n",
    "        # (since for t = 1 there are no previous latents to condition on)\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        # define a (trainable) parameter for the initial hidden state of the rnn\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim))\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        # if on gpu cuda-ize all PyTorch (sub)modules\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "        self.rnn_check = rnn_check\n",
    "        self.rpt = rpt\n",
    "\n",
    "    def forward(self, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths, annealing_factor=1.0):\n",
    "\n",
    "        # this is the number of time steps we need to process in the mini-batch\n",
    "        T_max = mini_batch.size(1)\n",
    "\n",
    "        # if on gpu we need the fully broadcast view of the rnn initial state\n",
    "        # to be in contiguous gpu memory\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0), self.rnn.hidden_size).contiguous()\n",
    "        # if any(torch.isnan(h_0_contig.reshape(-1))):\n",
    "        #     print(\"h_0_contig\")\n",
    "        # push the observed x's through the rnn;\n",
    "        # rnn_output contains the hidden state at each time step\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        if self.rnn_check:\n",
    "            if any(torch.isnan(rnn_output.data.reshape(-1))):\n",
    "                # print(\"rnn_output First\")\n",
    "                # print(self.rnn.state_dict().items())\n",
    "                # print(rnn_output)\n",
    "                # torch.save(rnn_output, \"out\")\n",
    "                # torch.save(self.rnn.state_dict().items, \"dic\")\n",
    "                # torch.save(mini_batch_reversed, \"mini_batch_reversed\")\n",
    "                # torch.save(h_0_contig, \"h_0_contig\")\n",
    "                assert False\n",
    "\n",
    "        # reverse the time-ordering in the hidden state and un-pack it\n",
    "        rnn_output = poly.pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "        # if any(torch.isnan(rnn_output.reshape(-1))):\n",
    "        #     print(\"rnn_output\")\n",
    "        # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "        # if any(torch.isnan(z_prev.reshape(-1))):\n",
    "        #     print(\"z_prev\")\n",
    "\n",
    "        x_container = []\n",
    "        for t in range(1,T_max+1):\n",
    "            # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\n",
    "            z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "\n",
    "            # Reparameterization Trick\n",
    "            eps = torch.randn(z_loc.size())\n",
    "            z_t = z_loc + z_scale * eps\n",
    "\n",
    "            # compute the probabilities that parameterize the bernoulli likelihood\n",
    "            emission_probs_t = self.emitter(z_t)\n",
    "\n",
    "            # the next statement instructs pyro to observe x_t according to the\n",
    "            # bernoulli distribution p(x_t|z_t)\n",
    "\n",
    "            #Reparameterization Trick\n",
    "            # eps = torch.rand(88)\n",
    "            # # assert len(emission_probs_t) == 88\n",
    "            # appxm = torch.log(eps) - torch.log(1-eps) + torch.log(probs) - torch.log(1-probs)\n",
    "            # x = torch.sigmoid(args)\n",
    "\n",
    "            # No Reparameterization Trick\n",
    "            x = emission_probs_t\n",
    "\n",
    "            #Reparameterization Trick\n",
    "            if self.rpt : \n",
    "                eps = torch.rand(88)\n",
    "                rpt_eps = 1e-20\n",
    "                # assert len(emission_probs_t) == 88\n",
    "                appxm = torch.log(eps + rpt_eps) - torch.log(1-eps + rpt_eps) + torch.log(x + rpt_eps) - torch.log(1-x + rpt_eps)\n",
    "                # appxm = torch.log(eps) - torch.log(1-eps) + torch.log(x) - torch.log(1-x)\n",
    "                x = torch.sigmoid(appxm)\n",
    "\n",
    "            # the latent sampled at this time step will be conditioned upon\n",
    "            # in the next time step so keep track of it\n",
    "            z_prev = z_t\n",
    "            x_container.append(x)\n",
    "\n",
    "        x_container = torch.stack(x_container)\n",
    "        return x_container.transpose(0,1)"
   ]
  },
  {
   "source": [
    "# Wasserstein Distance ( WGAN version )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_network(nn.Module):\n",
    "    def __init__(self, hiddden_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        ## the number of tones\n",
    "        self.song_size = 88\n",
    "        ## the length of each song\n",
    "        self.song_length = 8\n",
    "        \n",
    "        self.input_size = self.song_size * self.song_length\n",
    "        self.hidden_size = hiddden_dim\n",
    "\n",
    "        self.D =  nn.Sequential(\n",
    "                    nn.Linear(self.input_size, self.hidden_size),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Linear(self.hidden_size, 1))\n",
    "    \n",
    "    def forward(self, train_mini_batch, generated_mini_batch):\n",
    "        train_mini_batch =  train_mini_batch.reshape(len(train_mini_batch),-1)\n",
    "        generated_mini_batch = generated_mini_batch.reshape(len(generated_mini_batch),-1)\n",
    "        outputs_real = self.D(train_mini_batch)\n",
    "        outputs_fake = self.D(generated_mini_batch)\n",
    "        # print(outputs_real.size())\n",
    "        # print(outputs_real)\n",
    "        # print(outputs_fake.size())\n",
    "        # print(outputs_fake)\n",
    "        # if any(torch.isnan(outputs_real.reshape(-1))):\n",
    "        #     print(\"REAL\")\n",
    "        # if any(torch.isnan(generated_mini_batch.reshape(-1))):\n",
    "        #     print(\"GENERATED\")\n",
    "        # if any(torch.isnan(outputs_fake.reshape(-1))):\n",
    "        #     print(\"FAKE\")\n",
    "        # if torch.isnan(-(torch.mean(outputs_real) - torch.mean(outputs_fake))):\n",
    "        #     print(\"OUTPUT\")\n",
    "        return (torch.mean(outputs_real) - torch.mean(outputs_fake))\n",
    "\n",
    "\n",
    "\n",
    "class WassersteinLoss():\n",
    "    def __init__(self, WGAN_network, N_loops=5, lr=0.00001):\n",
    "        self.WGAN_network = WGAN_network\n",
    "        self.D = self.WGAN_network.D\n",
    "        self.optimizer = torch.optim.RMSprop(self.D.parameters(), lr=lr)\n",
    "        # self.optimizer = torch.optim.Adam(self.D.parameters(), lr=lr)\n",
    "        # the number of loops of calculation of Wass\n",
    "        self.N_loops = N_loops\n",
    "\n",
    "\n",
    "    def calc(self, train_mini_batch, generated_mini_batch):\n",
    "        # vanish grad_fn of DMM's parameters\n",
    "        no_grad_generated_mini_batch = torch.tensor(generated_mini_batch)\n",
    "\n",
    "        # activate grad_fn of Wass calculator's parameters \n",
    "        for p in self.D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        ### CALCULATION LOOP ###       \n",
    "        for i in range(self.N_loops):\n",
    "            # print(\"{0}%\".format(i*20))\n",
    "            # NaN_detect(self.D,i,\"Before calc\")\n",
    "            minus_loss = - self.WGAN_network(train_mini_batch, no_grad_generated_mini_batch)\n",
    "            # print(loss)\n",
    "            self.optimizer.zero_grad()\n",
    "            minus_loss.backward() # 勾配を計算\n",
    "            self.optimizer.step() # 重みパラメータを更新 (Algorithm 1のStep 6)\n",
    "\n",
    "            # NaN_detect(self.D,i,\"Before Clip\")\n",
    "            # 重みパラメータの値を-0.01から0.01の間にクリッピングする (Algorithm 1のStep 7)\n",
    "            for p in self.D.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "            # NaN_detect(self.D,i,\"After Clip\")            \n",
    "\n",
    "        # vanish grad_fn of Wass calculator's parameters\n",
    "        # because we don't need to update Wass calculator's parameters anymore\n",
    "        for p in self.D.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # calculate Wass without Wass calculator's parameters's grad_fn\n",
    "        loss = self.WGAN_network(train_mini_batch, generated_mini_batch)\n",
    "\n",
    "        # save model\n",
    "        # torch.save(self.D.state_dict(), \"D\")\n",
    "\n",
    "        # Wass is positive\n",
    "        return loss\n"
   ]
  },
  {
   "source": [
    "## Wasserstein calculator CHECKER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ドドド、レレレ、ミミミ、ドレミ\n",
    "def easyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(5):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(20+i*10)] = 1\n",
    "    for i in range(5,8):\n",
    "        training_data_sequences[i][0][int(110-i*10)  ] = 1\n",
    "        training_data_sequences[i][1][int(110-i*10)+2] = 1\n",
    "        training_data_sequences[i][2][int(110-i*10)+4] = 1\n",
    "        training_data_sequences[i][3][int(110-i*10)+5] = 1\n",
    "        training_data_sequences[i][4][int(110-i*10)+7] = 1\n",
    "        training_data_sequences[i][5][int(110-i*10)+9] = 1\n",
    "        training_data_sequences[i][6][int(110-i*10)+11] = 1\n",
    "        training_data_sequences[i][7][int(110-i*10)+12] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、レレレ\n",
    "def superEasyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(30+i*5)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、ドドド、ドドド\n",
    "def easiestTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(70)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "# training_seq_lengths, training_data_sequences = superEasyTones()\n",
    "training_seq_lengths, training_data_sequences = easyTones()\n",
    "# training_seq_lengths, training_data_sequences = easiestTones()\n",
    "N_train_data = len(training_seq_lengths)\n",
    "shuffled_indices = torch.randperm(N_train_data)\n",
    "mini_batch_indices = shuffled_indices\n",
    "mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "                = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                                        training_seq_lengths, cuda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dmm' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cbc6a4c0bb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_reversed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_mask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmini_batch_seq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerated_mini_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dmm' is not defined"
     ]
    }
   ],
   "source": [
    "generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask,  mini_batch_seq_lengths)\n",
    "generated_mini_batch.reshape(10,-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"saveData\", \"20210124_11_43\")\n",
    "# DMM_dics = torch.load(os.path.join(path,\"DMM_dic\"))\n",
    "DMM_dics = torch.load(\"Model\")\n",
    "# DMM_dic = DMM_dics[\"DMM_dic\"]\n",
    "# WN_dic = DMM_dics[\"WGAN_Network_dic\"]\n",
    "\n",
    "dmm = DMM(use_cuda=False, rnn_check=False, rpt=True)\n",
    "# WN = WGAN_network()\n",
    "# WN.load_state_dict(WN_dic())\n",
    "# W = WassersteinLoss(WN, N_loops=10, lr=0.00001)\n",
    "\n",
    "dmm.load_state_dict(DMM_dics)\n",
    "generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask,  mini_batch_seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 8, 1])\ntensor([[[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]],\n\n        [[0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196],\n         [0.0196]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = WN(mini_batch, generated_mini_batch)"
   ]
  },
  {
   "source": [
    "# NaN detector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_detect(NetWork, epoch, message=None):\n",
    "    flag = False\n",
    "    for name, site in NetWork.state_dict().items():\n",
    "        if any(torch.isnan(site.reshape(-1))):\n",
    "            flag = True\n",
    "            # if message != None:\n",
    "            #     print(message)\n",
    "            # print(\"Nan was detected!! at epoch %d\" % epoch)\n",
    "            # print(\"Para name is %s\" % name)\n",
    "    if flag:\n",
    "        if message != None:\n",
    "            print(message)\n",
    "        assert False"
   ]
  },
  {
   "source": [
    "# Generate audio data from trained DMM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Make and Save midi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_as_midi(song, length, path=\"\", name=\"default.mid\", BPM = 120, interval = 120, velocity = 127):\n",
    "#     mid = MidiFile()\n",
    "#     track = MidiTrack()\n",
    "#     mid.tracks.append(track)\n",
    "#     track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(BPM)))\n",
    "#     for tones in song:\n",
    "#         which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "#         if len(which_tone) == 0:\n",
    "#             track.append(Message('note_on', note=0, velocity=0, time=0))\n",
    "#             track.append(Message('note_off', note=0, time=interval))\n",
    "#         else:\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_on', note=int(which), velocity=velocity, time=0))\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_off', note=int(which), time=interval))\n",
    "#     mid.save(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_midi(song, path=\"\", name=\"default.mid\", BPM = 120, velocity = 100):\n",
    "    pm = pretty_midi.PrettyMIDI(resolution=960, initial_tempo=BPM) #pretty_midiオブジェクトを作ります\n",
    "    instrument = pretty_midi.Instrument(0) #instrumentはトラックみたいなものです。\n",
    "    for i,tones in enumerate(song):\n",
    "        which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "        print(which_tone)\n",
    "        if len(which_tone) == 0:\n",
    "            note = pretty_midi.Note(velocity=0, pitch=0, start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "            instrument.notes.append(note)\n",
    "        else:\n",
    "            for which in which_tone:\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=int(which), start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "                instrument.notes.append(note)\n",
    "                print(\"DONE\")\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(os.path.join(path, name)) #midiファイルを書き込みます。\n",
    "\n",
    "\n",
    "def midi_to_wav(midi_name, midi_path=\"\", wav_name = None, wav_path=\"\", rate=44100):\n",
    "    if wav_name == None:\n",
    "        wav_name = os.path.splitext(midi_name)[0]+ \".wav\"\n",
    "        print(wav_name)\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_name) #midiファイルを読み込みます\n",
    "    data = np.array(midi_data.synthesize()*1e5, dtype = \"int16\")\n",
    "    write(os.path.join(wav_path, wav_name), rate, data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate X\n",
    "def generate_Xs(dmm, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths):\n",
    "    songs_dic = {}\n",
    "    generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\n",
    "    for i, song in enumerate(generated_mini_batch):\n",
    "        tones_container = []\n",
    "        for time in range(mini_batch_seq_lengths[i]):\n",
    "            print(song[time])\n",
    "            p = dist.Bernoulli(probs=song[time])\n",
    "            tone = p.sample()\n",
    "            tones_container.append(tone)\n",
    "        tones_container = torch.stack(tones_container)\n",
    "        songs_dic.update([(\"song%02d\"%(i), tones_container)])\n",
    "    return songs_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'songs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f2e4985ef5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msongs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"song%02d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mNo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlengthG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_as_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Gen.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmidi_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Gen.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'songs' is not defined"
     ]
    }
   ],
   "source": [
    "No = 0\n",
    "song = songs[\"song%02d\"%No]\n",
    "lengthG = len(song)\n",
    "save_as_midi(song=song, name= \"Gen.mid\")\n",
    "midi_to_wav(midi_name=\"Gen.mid\")"
   ]
  },
  {
   "source": [
    "## Listen midi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_midi(name, path=\"\"):\n",
    "    ports = mido.get_output_names()\n",
    "    print(\"START\")\n",
    "    with mido.open_output(ports[0]) as outport:\n",
    "        for msg in mido.MidiFile(os.path.join(path,name)):\n",
    "            time.sleep(msg.time)\n",
    "            if not msg.is_meta:\n",
    "                # print(outport, msg)\n",
    "                outport.send(msg)\n",
    "    print(\"END\")"
   ]
  },
  {
   "source": [
    "## Prepare mini batch for genetating"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = torch.randperm(N_train_data)\n",
    "# print(\"Proceeding: %.2f \" % (epoch*100/5000) + \"%\")\n",
    "\n",
    "# process each mini-batch; this is where we take gradient steps\n",
    "which_mini_batch = 0\n",
    "\n",
    "# compute which sequences in the training set we should grab\n",
    "mini_batch_start = (which_mini_batch * mini_batch_size)\n",
    "mini_batch_end = np.min([(which_mini_batch + 1) * mini_batch_size, N_train_data])\n",
    "mini_batch_indices = shuffled_indices[mini_batch_start:mini_batch_end]\n",
    "\n",
    "# grab a fully prepped mini-batch using the helper function in the data loader\n",
    "mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "    = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                            training_seq_lengths, cuda=cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"saveData\", \"20210108_22_40\")\n",
    "# path = os.path.join(\"saveData\", \"20210115_12_21\")\n",
    "DMM_dics = torch.load(os.path.join(path,\"dic_epoch10000\"))\n",
    "DMM_dic = DMM_dics[\"DMM_dic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary from trained dmm\n",
    "# DMM_dic = torch.load(\"DMM_dic\")\n",
    "dmm = DMM()\n",
    "dmm.load_state_dict(DMM_dic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6095e-01, 2.2278e-03, 5.5382e-01, 5.5700e-03, 2.3650e-01, 6.4868e-02,\n        1.2129e-02, 2.7535e-02, 4.3838e-03, 1.2117e-01, 8.6409e-04, 9.0879e-01,\n        5.9167e-02, 2.4968e-04, 4.2447e-02, 1.9956e-03, 2.8833e-02, 1.3938e-02,\n        1.1116e-02, 1.1824e-03, 5.4859e-02, 1.0883e-02, 7.3318e-05, 8.9755e-01,\n        7.1660e-06, 3.9539e-07, 1.2400e-03, 2.4068e-06, 8.8086e-05, 1.8548e-06,\n        3.2337e-04, 2.3675e-06, 3.6256e-07, 6.6273e-07, 5.8286e-05, 2.2163e-04,\n        1.9368e-05, 7.1255e-05, 3.6057e-05, 3.6447e-04, 1.6090e-04, 4.7260e-04,\n        5.6313e-05, 1.6659e-04, 2.1741e-05, 5.6564e-05],\n       grad_fn=<SelectBackward>)\ntensor([4.5921e-03, 8.7800e-05, 6.5723e-02, 7.6254e-03, 2.1217e-04, 3.8921e-03,\n        1.0225e-03, 1.0854e-01, 1.4512e-02, 1.3909e-03, 2.8969e-03, 1.7104e-03,\n        8.8048e-04, 4.9963e-03, 4.6137e-04, 1.6711e-03, 9.0983e-04, 3.0354e-03,\n        1.9412e-02, 1.5002e-03, 1.3159e-03, 4.4799e-03, 6.4387e-04, 7.1104e-03,\n        3.6408e-03, 1.9670e-02, 3.9630e-04, 9.0570e-02, 5.2699e-03, 2.1982e-03,\n        3.1226e-01, 2.7684e-03, 2.0122e-03, 1.3086e-03, 5.8006e-04, 3.6996e-02,\n        1.5870e-01, 1.0270e-02, 1.0193e-02, 9.5587e-01, 4.7794e-02, 1.7904e-03,\n        6.8282e-02, 8.2660e-01, 3.6962e-01, 5.3302e-02, 4.7216e-01, 2.6049e-02,\n        7.2858e-02, 5.1886e-02, 4.6547e-01, 7.5437e-01, 2.3717e-04, 1.1554e-03,\n        2.1017e-01, 6.5180e-01, 7.4346e-01, 1.7225e-03, 2.4593e-01, 4.6236e-02,\n        5.6395e-02, 1.0121e-02, 8.8277e-03, 3.5865e-01, 2.3433e-03, 3.2357e-03,\n        4.7438e-03, 2.0811e-03, 2.8516e-02, 6.7853e-04, 8.2247e-03, 3.7781e-04,\n        1.1256e-02, 4.5172e-04, 1.5248e-04, 1.3473e-03, 3.6340e-03, 1.1048e-02,\n        1.5296e-03, 1.5794e-03, 6.6777e-03, 3.6652e-03, 6.3453e-04, 3.9847e-02,\n        1.4039e-03, 8.2967e-05, 2.1645e-03, 5.8679e-03],\n       grad_fn=<SelectBackward>)\ntensor([1.5527e-02, 3.3588e-04, 5.9587e-04, 2.6543e-02, 1.0049e-04, 4.1593e-05,\n        1.6343e-03, 2.6159e-04, 1.7910e-03, 4.0678e-04, 1.0887e-03, 1.0127e-03,\n        4.7910e-04, 6.1540e-04, 7.1484e-05, 1.3303e-04, 2.6751e-04, 1.9238e-03,\n        7.3487e-05, 9.6638e-04, 2.4659e-03, 6.1191e-04, 5.3013e-05, 7.3100e-04,\n        9.9546e-04, 7.3473e-04, 3.7463e-05, 2.8537e-02, 2.4978e-02, 1.8111e-04,\n        4.1075e-02, 1.1298e-03, 9.3514e-04, 1.2774e-02, 7.4913e-02, 8.4037e-03,\n        5.7811e-03, 8.6665e-02, 4.5182e-02, 1.6851e-01, 4.0633e-01, 2.0517e-01,\n        3.5738e-02, 9.1685e-01, 1.6125e-01, 3.9830e-01, 2.3282e-01, 8.7900e-02,\n        1.4816e-03, 1.9167e-01, 2.1270e-02, 8.6894e-01, 2.8204e-01, 7.8799e-02,\n        2.6300e-02, 1.0254e-01, 7.3874e-01, 2.6685e-03, 4.4347e-01, 1.2213e-01,\n        9.5144e-02, 9.7055e-01, 1.5886e-03, 2.2176e-01, 1.3074e-02, 5.0668e-03,\n        4.2343e-03, 2.1375e-04, 5.2438e-04, 1.1777e-06, 4.6933e-05, 3.3392e-04,\n        2.2767e-06, 5.2191e-05, 1.3920e-06, 2.3309e-05, 1.1079e-05, 1.3266e-04,\n        1.5544e-04, 1.1550e-03, 5.9233e-03, 1.5414e-03, 1.1022e-03, 4.0163e-04,\n        2.1486e-04, 2.0640e-03, 1.3840e-04, 1.6378e-02],\n       grad_fn=<SelectBackward>)\ntensor([2.3382e-03, 4.6743e-04, 6.6519e-06, 7.6312e-06, 1.9157e-05, 3.2562e-05,\n        1.7177e-05, 2.9455e-04, 3.8370e-06, 4.0862e-05, 1.4539e-06, 6.2355e-05,\n        8.7552e-05, 1.0474e-04, 2.6023e-05, 8.7684e-05, 1.4502e-05, 1.8961e-04,\n        4.8451e-04, 9.0737e-05, 2.8053e-04, 1.2710e-04, 3.4002e-05, 1.6274e-04,\n        5.1515e-04, 6.1742e-04, 1.3798e-05, 2.0545e-03, 5.5703e-04, 1.7283e-03,\n        4.6174e-03, 9.8274e-03, 2.3957e-03, 7.2991e-04, 4.7545e-03, 8.7703e-02,\n        5.7870e-02, 6.3639e-02, 4.4607e-01, 6.4997e-01, 3.8125e-03, 4.1411e-01,\n        1.8178e-01, 3.4318e-03, 7.4213e-01, 7.7173e-02, 1.5799e-01, 7.1699e-02,\n        1.3311e-03, 5.8551e-02, 5.6038e-04, 9.2065e-01, 1.8285e-03, 6.8896e-03,\n        7.9375e-01, 7.5845e-05, 9.5806e-01, 9.4970e-04, 2.5005e-02, 1.8081e-01,\n        4.6657e-02, 7.0011e-01, 1.8637e-03, 2.8493e-01, 1.1304e-03, 1.1950e-02,\n        1.0276e-02, 1.1605e-06, 6.1514e-04, 1.4573e-04, 1.6416e-05, 6.9228e-05,\n        1.5504e-07, 1.3107e-05, 1.8803e-06, 2.1197e-06, 4.0740e-05, 3.6058e-06,\n        5.0189e-04, 9.7439e-05, 7.2510e-05, 1.2967e-04, 1.7196e-05, 1.1191e-05,\n        5.5437e-06, 6.6357e-06, 6.4351e-04, 4.7191e-03],\n       grad_fn=<SelectBackward>)\ntensor([6.4452e-06, 1.8008e-04, 1.6458e-05, 6.2976e-04, 1.5074e-04, 6.6570e-04,\n        3.3231e-04, 1.4396e-04, 1.2460e-03, 4.3930e-04, 2.3466e-05, 6.1290e-06,\n        1.4817e-05, 2.3148e-05, 4.3887e-06, 4.4623e-04, 5.9834e-05, 2.5747e-03,\n        1.0107e-02, 9.3329e-06, 1.4723e-05, 1.6378e-04, 8.6688e-06, 2.4644e-04,\n        1.7489e-04, 4.7443e-05, 9.8063e-05, 1.4020e-03, 3.5330e-04, 3.8976e-04,\n        2.5349e-03, 9.8235e-06, 3.0511e-03, 1.7229e-04, 8.1979e-03, 5.8280e-02,\n        1.4743e-05, 1.1351e-02, 2.5463e-02, 4.5159e-03, 5.9842e-02, 9.6567e-02,\n        2.7454e-01, 2.2279e-03, 6.9351e-01, 2.2443e-01, 2.4738e-01, 5.5724e-01,\n        7.4100e-02, 3.7812e-01, 9.3508e-03, 2.2426e-03, 6.5900e-02, 1.4950e-01,\n        2.5305e-02, 1.6815e-03, 1.8341e-01, 2.3766e-03, 7.3420e-01, 8.7222e-01,\n        8.7138e-03, 3.2485e-01, 1.3785e-03, 8.4757e-02, 1.6955e-03, 3.0306e-02,\n        7.4545e-03, 1.5939e-04, 5.9194e-05, 4.5100e-05, 3.4906e-04, 7.4792e-05,\n        5.0609e-07, 1.5940e-04, 4.5964e-04, 3.5027e-06, 5.9543e-05, 1.1105e-03,\n        1.1910e-04, 1.2151e-05, 6.4714e-05, 4.0342e-04, 1.0804e-04, 1.9353e-04,\n        9.4133e-04, 2.7429e-05, 1.0649e-04, 1.0262e-04],\n       grad_fn=<SelectBackward>)\ntensor([5.9388e-04, 6.1314e-05, 2.1630e-05, 3.1867e-03, 9.1996e-04, 7.0957e-05,\n        3.3248e-05, 1.8242e-04, 5.2669e-05, 5.7640e-05, 1.8200e-05, 2.8054e-04,\n        7.7106e-04, 9.1994e-06, 7.8509e-05, 9.8788e-06, 7.3039e-05, 3.6747e-05,\n        2.6350e-04, 8.9013e-05, 1.3217e-04, 9.1964e-05, 8.4356e-06, 7.3419e-05,\n        1.4892e-04, 5.4334e-04, 4.1981e-05, 4.4433e-03, 1.1259e-02, 2.9191e-05,\n        4.2608e-03, 1.0716e-04, 1.5575e-02, 9.2054e-04, 3.0682e-03, 6.5967e-03,\n        2.5385e-04, 6.8454e-02, 6.6089e-03, 2.9871e-02, 8.9790e-03, 1.6202e-01,\n        2.1808e-02, 2.9915e-03, 6.8796e-01, 3.6729e-03, 2.6973e-02, 3.3640e-02,\n        7.9377e-04, 4.6775e-01, 5.2201e-04, 6.3677e-04, 4.5785e-02, 1.8877e-02,\n        3.5895e-02, 2.5220e-04, 5.5576e-01, 1.2709e-03, 9.3819e-01, 6.7289e-03,\n        2.9079e-02, 9.2106e-01, 3.6040e-02, 2.0547e-03, 3.5846e-03, 2.0318e-02,\n        3.9144e-02, 5.8911e-06, 4.6588e-04, 1.0908e-05, 5.7768e-05, 3.3966e-04,\n        1.2084e-06, 3.1349e-04, 9.7370e-06, 4.4070e-06, 2.1235e-05, 1.7230e-04,\n        6.2495e-05, 1.3048e-03, 3.4532e-04, 1.5624e-04, 8.3711e-05, 4.9588e-05,\n        1.7132e-04, 1.9550e-05, 4.6435e-04, 2.4586e-04],\n       grad_fn=<SelectBackward>)\ntensor([1.5427e-03, 3.4719e-04, 1.0436e-05, 3.7686e-03, 7.5315e-05, 2.0091e-04,\n        3.1390e-04, 7.1517e-04, 5.6347e-05, 2.7057e-04, 2.1259e-04, 5.0043e-03,\n        1.5056e-05, 1.3456e-04, 5.6010e-04, 1.0947e-03, 3.8561e-05, 3.9447e-04,\n        3.8168e-04, 2.3513e-04, 2.6355e-04, 6.4035e-04, 3.3193e-04, 1.2816e-04,\n        6.4664e-05, 7.0698e-04, 4.3532e-04, 6.6286e-02, 1.7450e-05, 2.1416e-03,\n        8.0664e-03, 8.2421e-03, 1.1592e-02, 5.6549e-03, 2.4281e-02, 1.5683e-03,\n        1.5839e-02, 4.6477e-01, 8.5366e-02, 1.0832e-01, 8.8929e-03, 3.0534e-01,\n        2.5977e-02, 9.8687e-01, 1.3473e-01, 1.1915e-01, 2.0146e-01, 4.6468e-02,\n        5.4513e-03, 2.1262e-02, 2.0578e-02, 2.2128e-01, 7.4277e-02, 1.8023e-01,\n        4.9671e-02, 2.3383e-01, 1.5277e-01, 3.0221e-04, 8.0219e-01, 5.2259e-03,\n        1.9292e-01, 6.5049e-02, 1.3560e-03, 2.3222e-02, 1.2093e-03, 1.0416e-04,\n        2.9844e-03, 1.8966e-03, 4.7048e-04, 4.0074e-05, 4.1149e-02, 6.4359e-06,\n        3.3595e-05, 3.7388e-05, 8.2592e-06, 8.2017e-06, 1.7385e-04, 6.3721e-04,\n        7.9877e-06, 1.0458e-04, 3.8920e-04, 3.7672e-04, 6.1794e-04, 1.2923e-03,\n        8.6365e-04, 1.8844e-04, 3.8374e-04, 1.1084e-02],\n       grad_fn=<SelectBackward>)\ntensor([5.6267e-05, 3.8644e-04, 4.1431e-05, 6.6637e-06, 2.7597e-06, 6.1089e-05,\n        1.1900e-03, 2.4080e-05, 9.1944e-06, 3.2953e-04, 3.8064e-05, 1.8941e-04,\n        3.4035e-05, 3.0568e-05, 2.8084e-05, 2.4370e-04, 1.3891e-04, 1.4707e-03,\n        1.0717e-04, 1.0096e-05, 4.0748e-05, 8.7696e-05, 4.7378e-05, 3.9912e-05,\n        3.6864e-02, 1.3345e-04, 1.9316e-05, 2.7958e-05, 2.2835e-03, 8.4506e-04,\n        9.4640e-04, 2.9347e-04, 1.1912e-03, 3.2591e-05, 3.6545e-03, 1.3059e-03,\n        5.1069e-04, 6.4126e-01, 7.5453e-01, 7.6134e-02, 6.2294e-03, 9.7996e-01,\n        2.2140e-01, 4.9598e-04, 6.4764e-01, 6.1132e-04, 5.7637e-01, 1.0459e-02,\n        4.7638e-03, 6.6717e-02, 6.7938e-02, 1.2179e-01, 2.9478e-04, 6.5010e-01,\n        8.7013e-02, 3.1620e-04, 1.7036e-01, 1.2604e-03, 5.7435e-01, 2.6160e-01,\n        2.1447e-01, 7.2034e-01, 1.1418e-01, 2.8985e-03, 1.6421e-05, 1.9190e-01,\n        3.4528e-05, 6.5616e-06, 7.0739e-04, 1.6250e-05, 1.4205e-05, 1.8624e-05,\n        3.6151e-07, 3.9746e-06, 3.7058e-06, 5.4155e-07, 1.6650e-04, 4.3858e-04,\n        3.4030e-05, 1.2596e-05, 5.2569e-03, 2.9423e-05, 1.5748e-04, 1.0010e-04,\n        6.4689e-06, 1.0447e-04, 8.2493e-05, 3.4921e-05],\n       grad_fn=<SelectBackward>)\ntensor([1.9078e-05, 1.4066e-05, 2.0112e-06, 3.2719e-05, 1.1078e-05, 4.8483e-07,\n        5.7596e-05, 4.7546e-06, 2.2085e-04, 1.5055e-06, 3.0067e-05, 6.1649e-06,\n        4.4285e-05, 5.5597e-06, 1.0366e-05, 5.8968e-05, 1.0189e-04, 4.0988e-05,\n        3.5692e-05, 1.7636e-06, 1.2197e-06, 1.4935e-04, 3.1950e-04, 1.0953e-05,\n        3.0939e-04, 1.0349e-05, 9.3623e-06, 3.9582e-05, 1.1092e-04, 3.3498e-05,\n        2.7633e-05, 1.8505e-03, 4.1269e-05, 4.6032e-06, 4.8733e-03, 2.6064e-04,\n        3.3772e-04, 1.3658e-02, 2.4987e-02, 2.9217e-01, 3.4433e-03, 3.2120e-03,\n        6.7751e-01, 2.6422e-02, 6.0623e-03, 3.8196e-05, 7.1080e-01, 2.7966e-03,\n        4.1256e-05, 2.6432e-01, 9.0476e-03, 6.0102e-01, 1.1799e-02, 5.0929e-01,\n        3.4054e-01, 2.7620e-03, 1.6283e-03, 1.1827e-05, 9.3268e-01, 1.4570e-03,\n        2.1590e-05, 2.8445e-03, 3.9944e-04, 8.0730e-03, 7.5682e-05, 4.2189e-01,\n        1.0035e-03, 5.8773e-05, 4.3108e-04, 1.8067e-07, 1.1107e-03, 6.5555e-07,\n        6.2055e-06, 1.1429e-05, 7.8446e-08, 1.4732e-06, 2.3126e-05, 8.7946e-05,\n        7.6844e-06, 2.8272e-05, 1.4306e-05, 1.4464e-04, 6.3846e-05, 1.8756e-04,\n        2.2343e-05, 6.6101e-05, 8.6261e-06, 2.2443e-05],\n       grad_fn=<SelectBackward>)\ntensor([4.3174e-03, 8.2526e-05, 6.2020e-02, 7.1706e-03, 1.9943e-04, 3.6591e-03,\n        9.6113e-04, 1.0269e-01, 1.3652e-02, 1.3074e-03, 2.7233e-03, 1.6078e-03,\n        8.2763e-04, 4.6976e-03, 4.3366e-04, 1.5708e-03, 8.5522e-04, 2.8535e-03,\n        1.8267e-02, 1.4102e-03, 1.2370e-03, 4.2119e-03, 5.8796e-04, 6.6861e-03,\n        3.4229e-03, 2.7365e-02, 3.7250e-04, 1.2389e-01, 6.9327e-03, 7.5406e-03,\n        3.5179e-01, 2.9418e-03, 7.3305e-03, 1.8418e-03, 2.3287e-03, 1.3377e-01,\n        5.1096e-01, 2.2503e-02, 1.6208e-02, 9.6727e-01, 1.4878e-01, 2.3823e-03,\n        4.0706e-02, 6.7187e-01, 5.4107e-01, 5.8181e-02, 1.1423e-01, 1.7783e-02,\n        1.1317e-01, 8.2413e-02, 3.0125e-01, 9.1985e-01, 3.8649e-04, 7.3258e-04,\n        1.6090e-01, 5.4270e-01, 8.9251e-01, 4.1035e-03, 3.5659e-01, 5.8643e-02,\n        1.5037e-01, 1.0173e-02, 3.1726e-03, 9.5617e-02, 1.7879e-03, 7.7575e-04,\n        4.8474e-04, 3.2431e-04, 1.5778e-02, 1.4924e-03, 4.2306e-03, 3.2493e-04,\n        1.7268e-02, 3.6698e-04, 9.7299e-05, 1.0098e-03, 3.4165e-03, 1.0391e-02,\n        1.4378e-03, 1.4847e-03, 6.2791e-03, 3.4457e-03, 5.9643e-04, 3.7543e-02,\n        1.3197e-03, 7.7984e-05, 2.0347e-03, 5.5174e-03],\n       grad_fn=<SelectBackward>)\ntensor([2.4320e-02, 5.3072e-04, 9.4138e-04, 4.1312e-02, 1.5880e-04, 6.5732e-05,\n        2.5804e-03, 4.1335e-04, 2.8276e-03, 6.4273e-04, 1.7196e-03, 1.5995e-03,\n        7.5696e-04, 9.7224e-04, 1.1297e-04, 2.1023e-04, 4.2271e-04, 3.0370e-03,\n        1.1613e-04, 1.5264e-03, 3.8916e-03, 9.6672e-04, 1.2807e-04, 1.1548e-03,\n        1.5723e-03, 1.8168e-03, 5.9205e-05, 1.7453e-01, 9.5388e-02, 4.9033e-04,\n        1.1908e-01, 7.8038e-03, 9.7910e-03, 1.0784e-02, 3.3003e-01, 7.3017e-02,\n        1.8631e-02, 1.7192e-01, 1.6018e-02, 3.8948e-01, 3.5323e-01, 1.6616e-01,\n        4.5889e-02, 9.7150e-01, 8.3831e-02, 2.6314e-01, 7.3866e-02, 8.5564e-02,\n        1.0435e-03, 3.6610e-01, 9.0344e-03, 9.7149e-01, 2.8646e-01, 1.1544e-02,\n        2.6532e-02, 1.4020e-01, 7.9842e-01, 3.6504e-03, 7.9697e-01, 1.8411e-01,\n        2.5959e-02, 9.0853e-01, 1.0906e-04, 5.0002e-02, 1.8464e-02, 2.2571e-04,\n        1.0933e-03, 2.1903e-04, 2.1828e-04, 3.6771e-06, 1.0694e-04, 1.0609e-03,\n        3.5192e-06, 1.4370e-04, 1.3444e-06, 6.8873e-05, 1.7510e-05, 2.0963e-04,\n        2.4564e-04, 1.8241e-03, 9.3291e-03, 2.4339e-03, 1.7408e-03, 6.3459e-04,\n        3.3953e-04, 3.2580e-03, 2.1872e-04, 2.5639e-02],\n       grad_fn=<SelectBackward>)\ntensor([4.8159e-03, 9.6466e-04, 1.3735e-05, 1.5757e-05, 3.9555e-05, 6.7230e-05,\n        3.5467e-05, 6.0799e-04, 7.9225e-06, 8.4367e-05, 3.0020e-06, 1.2874e-04,\n        1.8076e-04, 2.1624e-04, 5.3730e-05, 1.8103e-04, 2.9943e-05, 3.9143e-04,\n        9.9988e-04, 1.8733e-04, 5.7906e-04, 2.6240e-04, 5.6574e-05, 3.3596e-04,\n        1.0631e-03, 3.9601e-04, 2.8489e-05, 3.7807e-03, 1.2941e-03, 1.9121e-04,\n        1.6862e-03, 3.1122e-02, 6.1030e-04, 4.1184e-04, 7.3827e-03, 1.3312e-03,\n        7.9418e-03, 2.0600e-01, 4.3575e-01, 1.5064e-01, 4.7592e-02, 1.3191e-01,\n        5.6847e-02, 5.3819e-01, 3.2146e-01, 1.5047e-02, 6.5622e-01, 2.2433e-03,\n        7.3416e-03, 4.7274e-01, 6.9122e-04, 7.6341e-01, 9.6111e-02, 6.3073e-03,\n        1.5236e-01, 6.1262e-02, 8.4809e-01, 1.4326e-04, 7.5669e-01, 1.0947e-02,\n        4.2552e-03, 9.0965e-01, 1.9448e-03, 3.5170e-01, 1.0214e-01, 8.6303e-02,\n        2.4784e-02, 4.6930e-03, 3.1477e-04, 4.3541e-04, 2.5760e-04, 3.1371e-04,\n        5.5970e-06, 4.2044e-04, 1.9271e-05, 5.7084e-06, 8.4115e-05, 7.4451e-06,\n        1.0357e-03, 2.0117e-04, 1.4970e-04, 2.6769e-04, 3.5505e-05, 2.3106e-05,\n        1.1446e-05, 1.3701e-05, 1.3278e-03, 9.6951e-03],\n       grad_fn=<SelectBackward>)\ntensor([4.1059e-06, 1.1473e-04, 1.0485e-05, 4.0129e-04, 9.6033e-05, 4.2419e-04,\n        2.1172e-04, 9.1716e-05, 7.9413e-04, 2.7990e-04, 1.4950e-05, 3.9045e-06,\n        9.4390e-06, 1.4747e-05, 2.7958e-06, 2.8432e-04, 3.8118e-05, 1.6417e-03,\n        6.4626e-03, 5.9456e-06, 9.3794e-06, 1.0435e-04, 9.8650e-06, 1.5701e-04,\n        1.1142e-04, 6.1976e-06, 6.2474e-05, 1.0291e-03, 8.2945e-04, 1.8229e-04,\n        2.7829e-05, 8.5666e-06, 1.1355e-02, 4.1369e-04, 4.3199e-03, 9.1105e-02,\n        1.4035e-04, 3.0007e-03, 1.4308e-03, 9.4675e-03, 2.9027e-01, 1.5567e-01,\n        8.2162e-03, 6.4907e-03, 8.5037e-01, 3.8452e-01, 2.8666e-02, 9.3161e-01,\n        6.2909e-01, 5.7014e-03, 1.4665e-03, 8.8728e-03, 1.5264e-01, 3.7413e-02,\n        2.8501e-03, 5.1356e-02, 6.2474e-01, 2.8471e-03, 2.7105e-01, 9.0722e-01,\n        3.3352e-01, 2.2480e-01, 5.8586e-02, 7.5863e-01, 7.0658e-03, 5.8425e-03,\n        3.6139e-04, 5.1566e-04, 2.0429e-04, 6.8719e-05, 5.6622e-05, 4.7148e-04,\n        3.1418e-05, 3.5427e-04, 2.7287e-04, 1.7672e-05, 3.7933e-05, 7.0776e-04,\n        7.5875e-05, 7.7408e-06, 4.1228e-05, 2.5704e-04, 6.8828e-05, 1.2329e-04,\n        5.9988e-04, 1.7474e-05, 6.7842e-05, 6.5379e-05],\n       grad_fn=<SelectBackward>)\ntensor([3.6567e-04, 3.7745e-05, 1.3315e-05, 1.9641e-03, 5.6651e-04, 4.3681e-05,\n        2.0467e-05, 1.1230e-04, 3.2423e-05, 3.5483e-05, 1.1204e-05, 1.7271e-04,\n        4.7479e-04, 5.6630e-06, 4.8330e-05, 6.0813e-06, 4.4963e-05, 2.2621e-05,\n        1.6222e-04, 5.4797e-05, 8.1369e-05, 5.6613e-05, 1.3836e-05, 4.5197e-05,\n        9.1679e-05, 3.5320e-04, 2.5843e-05, 4.6560e-02, 8.0912e-02, 3.1030e-05,\n        1.1582e-03, 1.4597e-03, 3.3632e-01, 1.1658e-03, 2.8817e-03, 7.7073e-02,\n        2.6196e-03, 3.0570e-02, 4.7752e-04, 1.3269e-01, 1.0805e-01, 1.5219e-01,\n        1.6452e-03, 3.6046e-02, 8.8484e-01, 5.9948e-03, 4.3184e-03, 3.9137e-01,\n        4.1067e-03, 2.4024e-02, 7.9192e-05, 2.1621e-02, 2.5819e-01, 2.6019e-04,\n        2.9610e-02, 7.5500e-03, 7.2289e-01, 7.1957e-04, 8.7742e-01, 2.3605e-02,\n        1.6885e-01, 7.2759e-01, 4.0687e-02, 1.4875e-02, 2.2879e-02, 1.2241e-04,\n        8.9776e-03, 1.6138e-05, 9.8543e-05, 1.9875e-05, 1.4255e-05, 1.0579e-03,\n        7.3903e-06, 4.4313e-04, 3.1796e-06, 2.3006e-05, 1.3072e-05, 1.0607e-04,\n        3.8472e-05, 8.0359e-04, 2.1260e-04, 9.6185e-05, 5.1533e-05, 3.0526e-05,\n        1.0547e-04, 1.2035e-05, 2.8590e-04, 1.5136e-04],\n       grad_fn=<SelectBackward>)\ntensor([5.3144e-04, 1.1951e-04, 3.5916e-06, 1.3001e-03, 2.5920e-05, 6.9151e-05,\n        1.0805e-04, 2.4623e-04, 1.9392e-05, 9.3130e-05, 7.3169e-05, 1.7278e-03,\n        5.1813e-06, 4.6313e-05, 1.9282e-04, 3.7701e-04, 1.3271e-05, 1.3579e-04,\n        1.3139e-04, 8.0931e-05, 9.0714e-05, 2.2046e-04, 5.7290e-04, 4.4108e-05,\n        2.2254e-05, 3.1268e-03, 1.4985e-04, 4.5342e-03, 2.3245e-04, 1.4932e-02,\n        2.3586e-03, 4.2561e-03, 1.6694e-01, 5.6565e-04, 2.1041e-02, 6.7114e-03,\n        1.6784e-03, 9.3412e-01, 9.4174e-02, 1.6092e-01, 1.6342e-02, 7.1124e-01,\n        1.2572e-03, 3.1943e-01, 6.6393e-01, 2.4472e-02, 1.9450e-02, 3.3599e-01,\n        2.6128e-03, 7.2310e-02, 1.6796e-02, 6.5543e-02, 1.6579e-01, 4.4845e-01,\n        9.3661e-04, 5.3680e-03, 4.1877e-01, 2.9629e-05, 2.0364e-01, 1.6637e-01,\n        4.8735e-02, 3.7953e-01, 1.2833e-03, 2.1306e-04, 7.2019e-04, 1.7920e-05,\n        2.2581e-05, 7.7149e-06, 4.3541e-03, 1.3528e-05, 7.3194e-03, 5.3652e-05,\n        1.0992e-05, 6.3626e-05, 5.9442e-06, 6.5130e-06, 5.9835e-05, 2.1938e-04,\n        2.7489e-06, 3.5991e-05, 1.3397e-04, 1.2968e-04, 2.1274e-04, 4.4512e-04,\n        2.9738e-04, 6.4857e-05, 1.3209e-04, 3.8425e-03],\n       grad_fn=<SelectBackward>)\ntensor([2.6603e-05, 1.8274e-04, 1.9588e-05, 3.1505e-06, 1.3047e-06, 2.8882e-05,\n        5.6296e-04, 1.1385e-05, 4.3469e-06, 1.5582e-04, 1.7996e-05, 8.9557e-05,\n        1.6091e-05, 1.4452e-05, 1.3278e-05, 1.1523e-04, 6.5679e-05, 6.9585e-04,\n        5.0672e-05, 4.7734e-06, 1.9265e-05, 4.1463e-05, 1.5088e-05, 1.8870e-05,\n        1.7774e-02, 1.6870e-04, 9.1325e-06, 9.7108e-04, 1.4416e-03, 2.9937e-04,\n        1.4337e-03, 6.0347e-03, 5.1739e-02, 2.1080e-05, 5.6142e-04, 4.7193e-02,\n        2.3066e-02, 3.6702e-01, 1.6646e-03, 2.5742e-01, 1.2770e-03, 1.4329e-01,\n        6.0321e-01, 6.0714e-02, 8.1222e-01, 8.8298e-04, 9.3809e-02, 1.0509e-02,\n        3.2422e-02, 1.0598e-02, 2.4282e-05, 9.9859e-01, 1.6660e-03, 9.9225e-04,\n        2.7176e-01, 2.1804e-03, 1.3254e-01, 2.2360e-03, 3.9718e-01, 7.6189e-01,\n        4.3863e-01, 1.1087e-02, 1.0610e-05, 4.9721e-03, 1.3313e-04, 1.5868e-04,\n        3.7827e-03, 2.6720e-03, 2.4280e-04, 5.4182e-05, 6.2943e-06, 7.7182e-05,\n        7.6397e-07, 1.4813e-06, 1.4541e-07, 1.4662e-06, 7.8723e-05, 2.0740e-04,\n        1.6089e-05, 5.9551e-06, 2.4922e-03, 1.3911e-05, 7.4459e-05, 4.7328e-05,\n        3.0584e-06, 4.9395e-05, 3.9003e-05, 1.6510e-05],\n       grad_fn=<SelectBackward>)\ntensor([3.3530e-05, 2.4722e-05, 3.5349e-06, 5.7506e-05, 1.9471e-05, 8.5214e-07,\n        1.0123e-04, 8.3568e-06, 3.8810e-04, 2.6461e-06, 5.2844e-05, 1.0835e-05,\n        7.7833e-05, 9.7717e-06, 1.8220e-05, 1.0364e-04, 1.7906e-04, 7.2039e-05,\n        6.2731e-05, 3.0997e-06, 2.1438e-06, 2.6248e-04, 1.0521e-03, 1.9251e-05,\n        5.4366e-04, 5.3587e-04, 1.6455e-05, 1.8883e-05, 5.4349e-03, 1.1681e-02,\n        4.4189e-05, 1.7111e-03, 3.1970e-03, 1.5082e-03, 4.6006e-03, 1.4665e-02,\n        1.4449e-02, 1.0158e-01, 1.8599e-02, 3.4712e-01, 2.6062e-01, 3.2534e-02,\n        2.3676e-01, 4.5399e-04, 5.6492e-01, 6.7861e-03, 5.4067e-02, 4.5879e-01,\n        1.6488e-02, 1.9068e-01, 2.0147e-03, 6.9465e-01, 1.6757e-01, 4.3622e-01,\n        2.1495e-01, 2.3359e-04, 5.8578e-02, 2.2130e-04, 2.5878e-03, 2.1942e-02,\n        7.5675e-04, 1.2660e-03, 3.5132e-04, 1.9207e-03, 3.5258e-04, 2.5626e-02,\n        6.3901e-06, 7.2241e-08, 1.1439e-04, 1.2910e-06, 5.9670e-06, 1.2785e-06,\n        1.9564e-05, 9.5371e-07, 2.6747e-08, 6.1221e-07, 4.0646e-05, 1.5457e-04,\n        1.3506e-05, 4.9690e-05, 2.5144e-05, 2.5419e-04, 1.1221e-04, 3.2961e-04,\n        3.9270e-05, 1.1617e-04, 1.5161e-05, 3.9445e-05],\n       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "songs = generate_Xs(dmm, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([39, 43, 46, 50, 51])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([43, 45, 51, 56, 61])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([36, 37, 38, 39, 42, 46, 51, 56, 61, 63])\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([41, 42, 44, 58])\nDONE\nDONE\nDONE\nDONE\ntensor([32, 44, 58, 60])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 44, 49, 56])\nDONE\nDONE\nDONE\nDONE\ntensor([37, 38, 41, 42, 51, 53, 54, 58, 61])\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([38, 40, 53])\nDONE\nDONE\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\ntensor([20])\nDONE\n"
     ]
    }
   ],
   "source": [
    "No = 0\n",
    "song = songs[\"song%02d\"%No]\n",
    "lengthG = len(song)\n",
    "save_as_midi(song=song, name=\"Gen.mid\")\n",
    "\n",
    "song = mini_batch[No]\n",
    "lengthT = mini_batch_seq_lengths[No]\n",
    "save_as_midi(song=song, name=\"Tra.mid\")\n",
    "\n",
    "# song = training_data_sequences[0]\n",
    "# lengthT = 8\n",
    "# save_as_midi(song=song, length = lengthT, name=\"Tra.mid\",interval=240)\n",
    "\n",
    "# if lengthG == lengthT:\n",
    "#     print(lengthG)\n",
    "# else:\n",
    "#     assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'rtmidi' has no attribute 'API_UNSPECIFIED'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3948df1c2273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saveData\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"20210115_12_21\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tra.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gen.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# listen_midi(os.path.join(path, \"Training_Epoch%d.mid\"%epoch_number))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-0de5f9f72f83>\u001b[0m in \u001b[0;36mlisten_midi\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"START\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutport\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/backend.py\u001b[0m in \u001b[0;36mget_output_names\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;34m\"\"\"Return a sorted list of all output port names.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/backend.py\u001b[0m in \u001b[0;36m_get_devices\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_devices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/rtmidi.py\u001b[0m in \u001b[0;36mget_devices\u001b[0;34m(api, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mrtapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_api_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiIn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/rtmidi.py\u001b[0m in \u001b[0;36m_get_api_id\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_api_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrtmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI_UNSPECIFIED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'rtmidi' has no attribute 'API_UNSPECIFIED'"
     ]
    }
   ],
   "source": [
    "# path = os.path.join(\"saveData\", \"20210108_22_40\")\n",
    "path = os.path.join(\"saveData\", \"20210115_12_21\")\n",
    "epoch_number = 20000\n",
    "listen_midi(\"Tra.mid\")\n",
    "listen_midi(\"Gen.mid\")\n",
    "# listen_midi(os.path.join(path, \"Training_Epoch%d.mid\"%epoch_number))\n",
    "# listen_midi(os.path.join(path, \"Generated_Epoch%d.mid\"%epoch_number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
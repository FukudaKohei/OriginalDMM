{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from os.path import exists\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import TransformedDistribution\n",
    "from pyro.distributions.transforms import affine_autoregressive\n",
    "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceEnum_ELBO, TraceTMC_ELBO, config_enumerate\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "import pretty_midi\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import wave\n",
    "from scipy.io.wavfile import write\n",
    "# import fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## args\n",
    "num_epochs=5000\n",
    "learning_rate=0.003\n",
    "rpt_eps = 1e-20\n",
    "rnn_clamp = 1.\n",
    "# learning_rate=0.0003\n",
    "beta1=0.96\n",
    "beta2=0.999\n",
    "clip_norm=10.0\n",
    "lr_decay=0.99996\n",
    "mini_batch_size=20\n",
    "annealing_epochs=1000\n",
    "minimum_annealing_factor=0.2\n",
    "rnn_dropout_rate=0.1\n",
    "num_iafs=0\n",
    "iaf_dim=100\n",
    "checkpoint_freq=100\n",
    "load_opt=''\n",
    "load_model=''\n",
    "save_opt=''\n",
    "save_model=''\n",
    "cuda=False\n",
    "jit=False\n",
    "tmc=False\n",
    "tmcelbo=False\n",
    "rpt = True\n",
    "tmc_num_samples=10\n",
    "log='dmm.log'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 長さ最長129、例えば長さが60のやつは61~129はすべて0データ\n",
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "training_seq_lengths = data['train']['sequence_lengths']\n",
    "training_data_sequences = data['train']['sequences']\n",
    "\n",
    "## super easy training set\n",
    "# training_seq_lengths = torch.tensor([8])\n",
    "# training_data_sequences = torch.zeros(10,8,88)\n",
    "# for i in range(5):\n",
    "#     for j in range(8):\n",
    "#         training_data_sequences[i][j][int(20+i*10)] = 1\n",
    "# for i in range(5,8):\n",
    "#     training_data_sequences[i][0][int(110-i*10)  ] = 1\n",
    "#     training_data_sequences[i][1][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][2][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][3][int(110-i*10)+1] = 1\n",
    "#     training_data_sequences[i][4][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][5][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][6][int(110-i*10)+2] = 1\n",
    "#     training_data_sequences[i][7][int(110-i*10)+1] = 1\n",
    "\n",
    "test_seq_lengths = data['test']['sequence_lengths']\n",
    "test_data_sequences = data['test']['sequences']\n",
    "val_seq_lengths = data['valid']['sequence_lengths']\n",
    "val_data_sequences = data['valid']['sequences']\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = float(torch.sum(training_seq_lengths))\n",
    "N_mini_batches = int(N_train_data / mini_batch_size +\n",
    "                    int(N_train_data % mini_batch_size > 0))\n",
    "\n",
    "\n",
    "# how often we do validation/test evaluation during training\n",
    "val_test_frequency = 50\n",
    "# the number of samples we use to do the evaluation\n",
    "n_eval_samples = 1\n",
    "\n",
    "# rep is short for \"repeat\"\n",
    "# which means how many times we use certain sample to do validation/test evaluation during training\n",
    "def rep(x):\n",
    "        rep_shape = torch.Size([x.size(0) * n_eval_samples]) + x.size()[1:]\n",
    "        repeat_dims = [1] * len(x.size())\n",
    "        repeat_dims[0] = n_eval_samples\n",
    "        return x.repeat(repeat_dims).reshape(n_eval_samples, -1).transpose(1, 0).reshape(rep_shape)\n",
    "\n",
    "# get the validation/test data ready for the dmm: pack into sequences, etc.\n",
    "val_seq_lengths = rep(val_seq_lengths)\n",
    "test_seq_lengths = rep(test_seq_lengths)\n",
    "val_batch, val_batch_reversed, val_batch_mask, val_seq_lengths = poly.get_mini_batch(\n",
    "    torch.arange(n_eval_samples * val_data_sequences.shape[0]), rep(val_data_sequences),\n",
    "    val_seq_lengths, cuda=cuda)\n",
    "test_batch, test_batch_reversed, test_batch_mask, test_seq_lengths = poly.get_mini_batch(\n",
    "    torch.arange(n_eval_samples * test_data_sequences.shape[0]), rep(test_data_sequences),\n",
    "    test_seq_lengths, cuda=cuda)"
   ]
  },
  {
   "source": [
    "# Emitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the bernoulli observation likelihood `p(x_t | z_t)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim)\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim)\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z_t):\n",
    "        \"\"\"\n",
    "        Given the latent z at a particular time step t we return the vector of\n",
    "        probabilities `ps` that parameterizes the bernoulli distribution `p(x_t|z_t)`\n",
    "        \"\"\"\n",
    "        h1 = self.relu(self.lin_z_to_hidden(z_t))\n",
    "        h2 = self.relu(self.lin_hidden_to_hidden(h1))\n",
    "        ps = torch.sigmoid(self.lin_hidden_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "source": [
    "# Transmitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the gaussian latent transition probability `p(z_t | z_{t-1})`\n",
    "    See section 5 in the reference for comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # initialize the six linear transformations used in the neural network\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim)\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        # modify the default initialization of lin_z_to_loc\n",
    "        # so that it's starts out as the identity function\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        # initialize the three non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1):\n",
    "        \"\"\"\n",
    "        Given the latent `z_{t-1}` corresponding to the time step t-1\n",
    "        we return the mean and scale vectors that parameterize the\n",
    "        (diagonal) gaussian distribution `p(z_t | z_{t-1})`\n",
    "        \"\"\"\n",
    "        # compute the gating function\n",
    "        _gate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\n",
    "        gate = torch.sigmoid(self.lin_gate_hidden_to_z(_gate))\n",
    "        # compute the 'proposed mean'\n",
    "        _proposed_mean = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\n",
    "        # assemble the actual mean used to sample z_t, which mixes a linear transformation\n",
    "        # of z_{t-1} with the proposed mean modulated by the gating function\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\n",
    "        # compute the scale used to sample z_t, using the proposed mean from\n",
    "        # above as input the softplus ensures that scale is positive\n",
    "        scale = self.softplus(self.lin_sig(self.relu(proposed_mean)))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale\n"
   ]
  },
  {
   "source": [
    "# Combiner"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes `q(z_t | z_{t-1}, x_{t:T})`, which is the basic building block\n",
    "    of the guide (i.e. the variational distribution). The dependence on `x_{t:T}` is\n",
    "    through the hidden state of the RNN (see the PyTorch module `rnn` below)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        \"\"\"\n",
    "        Given the latent z at at a particular time step t-1 as well as the hidden\n",
    "        state of the RNN `h(x_{t:T})` we return the mean and scale vectors that\n",
    "        parameterize the (diagonal) gaussian distribution `q(z_t | z_{t-1}, x_{t:T})`\n",
    "        \"\"\"\n",
    "        # combine the rnn hidden state with a transformed version of z_t_1\n",
    "        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        # use the combined hidden state to compute the mean used to sample z_t\n",
    "        loc = self.lin_hidden_to_loc(h_combined)\n",
    "        # use the combined hidden state to compute the scale used to sample z_t\n",
    "        scale = self.softplus(self.lin_hidden_to_scale(h_combined))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale\n"
   ]
  },
  {
   "source": [
    "# Deep Markov Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    This PyTorch Module encapsulates the model as well as the\n",
    "    variational distribution (the guide) for the Deep Markov Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=88, z_dim=100, emission_dim=100,\n",
    "                 transition_dim=200, rnn_dim=600, num_layers=1, rnn_dropout_rate=0.1,\n",
    "                 num_iafs=0, iaf_dim=50, use_cuda=False, rnn_check=False, rpt=True):\n",
    "        super().__init__()\n",
    "        # instantiate PyTorch modules used in the model and guide below\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        # dropout just takes effect on inner layers of rnn\n",
    "        rnn_dropout_rate = 0. if num_layers == 1 else rnn_dropout_rate\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=rnn_dim, nonlinearity='relu',\n",
    "                          batch_first=True, bidirectional=False, num_layers=num_layers,\n",
    "                          dropout=rnn_dropout_rate)\n",
    "\n",
    "        # if we're using normalizing flows, instantiate those too\n",
    "        self.iafs = [affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)]\n",
    "        self.iafs_modules = nn.ModuleList(self.iafs)\n",
    "\n",
    "        # define a (trainable) parameters z_0 and z_q_0 that help define the probability\n",
    "        # distributions p(z_1) and q(z_1)\n",
    "        # (since for t = 1 there are no previous latents to condition on)\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        # define a (trainable) parameter for the initial hidden state of the rnn\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim))\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        # if on gpu cuda-ize all PyTorch (sub)modules\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "        self.rnn_check = rnn_check\n",
    "        self.rpt = rpt\n",
    "\n",
    "    def forward(self, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths, annealing_factor=1.0):\n",
    "\n",
    "        # this is the number of time steps we need to process in the mini-batch\n",
    "        T_max = mini_batch.size(1)\n",
    "\n",
    "        # if on gpu we need the fully broadcast view of the rnn initial state\n",
    "        # to be in contiguous gpu memory\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0), self.rnn.hidden_size).contiguous()\n",
    "        # if any(torch.isnan(h_0_contig.reshape(-1))):\n",
    "        #     print(\"h_0_contig\")\n",
    "        # push the observed x's through the rnn;\n",
    "        # rnn_output contains the hidden state at each time step\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        if self.rnn_check:\n",
    "            if any(torch.isnan(rnn_output.data.reshape(-1))):\n",
    "                # print(\"rnn_output First\")\n",
    "                # print(self.rnn.state_dict().items())\n",
    "                # print(rnn_output)\n",
    "                # torch.save(rnn_output, \"out\")\n",
    "                # torch.save(self.rnn.state_dict().items, \"dic\")\n",
    "                # torch.save(mini_batch_reversed, \"mini_batch_reversed\")\n",
    "                # torch.save(h_0_contig, \"h_0_contig\")\n",
    "                assert False\n",
    "\n",
    "        # reverse the time-ordering in the hidden state and un-pack it\n",
    "        rnn_output = poly.pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "        # if any(torch.isnan(rnn_output.reshape(-1))):\n",
    "        #     print(\"rnn_output\")\n",
    "        # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "        # if any(torch.isnan(z_prev.reshape(-1))):\n",
    "        #     print(\"z_prev\")\n",
    "\n",
    "        x_container = []\n",
    "        for t in range(1,T_max+1):\n",
    "            # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\n",
    "            z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "\n",
    "            # Reparameterization Trick\n",
    "            eps = torch.randn(z_loc.size())\n",
    "            z_t = z_loc + z_scale * eps\n",
    "\n",
    "            # compute the probabilities that parameterize the bernoulli likelihood\n",
    "            emission_probs_t = self.emitter(z_t)\n",
    "\n",
    "            # the next statement instructs pyro to observe x_t according to the\n",
    "            # bernoulli distribution p(x_t|z_t)\n",
    "\n",
    "            #Reparameterization Trick\n",
    "            # eps = torch.rand(88)\n",
    "            # # assert len(emission_probs_t) == 88\n",
    "            # appxm = torch.log(eps) - torch.log(1-eps) + torch.log(probs) - torch.log(1-probs)\n",
    "            # x = torch.sigmoid(args)\n",
    "\n",
    "            # No Reparameterization Trick\n",
    "            x = emission_probs_t\n",
    "\n",
    "            #Reparameterization Trick\n",
    "            if self.rpt : \n",
    "                eps = torch.rand(88)\n",
    "                rpt_eps = 1e-20\n",
    "                # assert len(emission_probs_t) == 88\n",
    "                appxm = torch.log(eps + rpt_eps) - torch.log(1-eps + rpt_eps) + torch.log(x + rpt_eps) - torch.log(1-x + rpt_eps)\n",
    "                # appxm = torch.log(eps) - torch.log(1-eps) + torch.log(x) - torch.log(1-x)\n",
    "                x = torch.sigmoid(appxm)\n",
    "\n",
    "            # the latent sampled at this time step will be conditioned upon\n",
    "            # in the next time step so keep track of it\n",
    "            z_prev = z_t\n",
    "            x_container.append(x)\n",
    "\n",
    "        x_container = torch.stack(x_container)\n",
    "        return x_container.transpose(0,1)"
   ]
  },
  {
   "source": [
    "# Wasserstein Distance ( WGAN version )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_network(nn.Module):\n",
    "    def __init__(self, hiddden_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        ## the number of tones\n",
    "        self.song_size = 88\n",
    "        ## the length of each song\n",
    "        self.song_length = 8\n",
    "        \n",
    "        self.input_size = self.song_size * self.song_length\n",
    "        self.hidden_size = hiddden_dim\n",
    "\n",
    "        self.D =  nn.Sequential(\n",
    "                    nn.Linear(self.input_size, self.hidden_size),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Linear(self.hidden_size, 1))\n",
    "    \n",
    "    def forward(self, train_mini_batch, generated_mini_batch):\n",
    "        train_mini_batch =  train_mini_batch.reshape(len(train_mini_batch),-1)\n",
    "        generated_mini_batch = generated_mini_batch.reshape(len(generated_mini_batch),-1)\n",
    "        outputs_real = self.D(train_mini_batch)\n",
    "        outputs_fake = self.D(generated_mini_batch)\n",
    "        # print(outputs_real.size())\n",
    "        # print(outputs_real)\n",
    "        # print(outputs_fake.size())\n",
    "        # print(outputs_fake)\n",
    "        # if any(torch.isnan(outputs_real.reshape(-1))):\n",
    "        #     print(\"REAL\")\n",
    "        # if any(torch.isnan(generated_mini_batch.reshape(-1))):\n",
    "        #     print(\"GENERATED\")\n",
    "        # if any(torch.isnan(outputs_fake.reshape(-1))):\n",
    "        #     print(\"FAKE\")\n",
    "        # if torch.isnan(-(torch.mean(outputs_real) - torch.mean(outputs_fake))):\n",
    "        #     print(\"OUTPUT\")\n",
    "        return (torch.mean(outputs_real) - torch.mean(outputs_fake))\n",
    "\n",
    "\n",
    "\n",
    "class WassersteinLoss():\n",
    "    def __init__(self, WGAN_network, N_loops=5, lr=0.00001):\n",
    "        self.WGAN_network = WGAN_network\n",
    "        self.D = self.WGAN_network.D\n",
    "        self.optimizer = torch.optim.RMSprop(self.D.parameters(), lr=lr)\n",
    "        # self.optimizer = torch.optim.Adam(self.D.parameters(), lr=lr)\n",
    "        # the number of loops of calculation of Wass\n",
    "        self.N_loops = N_loops\n",
    "\n",
    "\n",
    "    def calc(self, train_mini_batch, generated_mini_batch):\n",
    "        # vanish grad_fn of DMM's parameters\n",
    "        no_grad_generated_mini_batch = torch.tensor(generated_mini_batch)\n",
    "\n",
    "        # activate grad_fn of Wass calculator's parameters \n",
    "        for p in self.D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        ### CALCULATION LOOP ###       \n",
    "        for i in range(self.N_loops):\n",
    "            # print(\"{0}%\".format(i*20))\n",
    "            # NaN_detect(self.D,i,\"Before calc\")\n",
    "            minus_loss = - self.WGAN_network(train_mini_batch, no_grad_generated_mini_batch)\n",
    "            # print(loss)\n",
    "            self.optimizer.zero_grad()\n",
    "            minus_loss.backward() # 勾配を計算\n",
    "            self.optimizer.step() # 重みパラメータを更新 (Algorithm 1のStep 6)\n",
    "\n",
    "            # NaN_detect(self.D,i,\"Before Clip\")\n",
    "            # 重みパラメータの値を-0.01から0.01の間にクリッピングする (Algorithm 1のStep 7)\n",
    "            for p in self.D.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "            # NaN_detect(self.D,i,\"After Clip\")            \n",
    "\n",
    "        # vanish grad_fn of Wass calculator's parameters\n",
    "        # because we don't need to update Wass calculator's parameters anymore\n",
    "        for p in self.D.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # calculate Wass without Wass calculator's parameters's grad_fn\n",
    "        loss = self.WGAN_network(train_mini_batch, generated_mini_batch)\n",
    "\n",
    "        # save model\n",
    "        # torch.save(self.D.state_dict(), \"D\")\n",
    "\n",
    "        # Wass is positive\n",
    "        return loss\n"
   ]
  },
  {
   "source": [
    "# NaN detector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_detect(NetWork, epoch, message=None):\n",
    "    flag = False\n",
    "    for name, site in NetWork.state_dict().items():\n",
    "        if any(torch.isnan(site.reshape(-1))):\n",
    "            flag = True\n",
    "            # if message != None:\n",
    "            #     print(message)\n",
    "            # print(\"Nan was detected!! at epoch %d\" % epoch)\n",
    "            # print(\"Para name is %s\" % name)\n",
    "    if flag:\n",
    "        if message != None:\n",
    "            print(message)\n",
    "        assert False"
   ]
  },
  {
   "source": [
    "# Make and Save midi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_as_midi(song, length, path=\"\", name=\"default.mid\", BPM = 120, interval = 120, velocity = 127):\n",
    "#     mid = MidiFile()\n",
    "#     track = MidiTrack()\n",
    "#     mid.tracks.append(track)\n",
    "#     track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(BPM)))\n",
    "#     for tones in song:\n",
    "#         which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "#         if len(which_tone) == 0:\n",
    "#             track.append(Message('note_on', note=0, velocity=0, time=0))\n",
    "#             track.append(Message('note_off', note=0, time=interval))\n",
    "#         else:\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_on', note=int(which), velocity=velocity, time=0))\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_off', note=int(which), time=interval))\n",
    "#     mid.save(os.path.join(path, name))\n",
    "\n",
    "def save_as_midi(song, path=\"\", name=\"default.mid\", BPM = 120, velocity = 100):\n",
    "    pm = pretty_midi.PrettyMIDI(resolution=960, initial_tempo=BPM) #pretty_midiオブジェクトを作ります\n",
    "    instrument = pretty_midi.Instrument(0) #instrumentはトラックみたいなものです。\n",
    "    for i,tones in enumerate(song):\n",
    "        which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "        print(which_tone)\n",
    "        if len(which_tone) == 0:\n",
    "            note = pretty_midi.Note(velocity=0, pitch=0, start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "            instrument.notes.append(note)\n",
    "        else:\n",
    "            for which in which_tone:\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=int(which), start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "                instrument.notes.append(note)\n",
    "                print(\"DONE\")\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(os.path.join(path, name)) #midiファイルを書き込みます。\n",
    "\n",
    "\n",
    "def midi_to_wav(midi_name, midi_path=\"\", wav_name = None, wav_path=\"\", rate=44100):\n",
    "    if wav_name == None:\n",
    "        wav_name = os.path.splitext(midi_name)[0]+ \".wav\"\n",
    "        print(wav_name)\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_name) #midiファイルを読み込みます\n",
    "    data = np.array(midi_data.synthesize()*1e5, dtype = \"int16\")\n",
    "    write(os.path.join(wav_path, wav_name), rate, data )"
   ]
  },
  {
   "source": [
    "# Generate Xs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate X\n",
    "def generate_Xs(dmm, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths):\n",
    "    songs_dic = {}\n",
    "    generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\n",
    "    for i, song in enumerate(generated_mini_batch):\n",
    "        tones_container = []\n",
    "        for time in range(mini_batch_seq_lengths[i]):\n",
    "            print(song[time])\n",
    "            p = dist.Bernoulli(probs=song[time])\n",
    "            tone = p.sample()\n",
    "            tones_container.append(tone)\n",
    "        tones_container = torch.stack(tones_container)\n",
    "        songs_dic.update([(\"song%02d\"%(i), tones_container)])\n",
    "    return songs_dic"
   ]
  },
  {
   "source": [
    "# Listen midi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_midi(name, path=\"\"):\n",
    "    ports = mido.get_output_names()\n",
    "    print(\"START\")\n",
    "    with mido.open_output(ports[0]) as outport:\n",
    "        for msg in mido.MidiFile(os.path.join(path,name)):\n",
    "            time.sleep(msg.time)\n",
    "            if not msg.is_meta:\n",
    "                # print(outport, msg)\n",
    "                outport.send(msg)\n",
    "    print(\"END\")"
   ]
  },
  {
   "source": [
    "# MONITOR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_detect(NetWork, epoch, message=None):\n",
    "    flag = False\n",
    "    for name, site in NetWork.state_dict().items():\n",
    "        if any(torch.isnan(site.reshape(-1))):\n",
    "            flag = True\n",
    "            # if message != None:\n",
    "            #     print(message)\n",
    "            # print(\"Nan was detected!! at epoch %d\" % epoch)\n",
    "            # print(\"Para name is %s\" % name)\n",
    "    if flag:\n",
    "        if message != None:\n",
    "            print(message)\n",
    "        assert False"
   ]
  },
  {
   "source": [
    "## Make and Save midi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_as_midi(song, length, path=\"\", name=\"default.mid\", BPM = 120, interval = 120, velocity = 127):\n",
    "#     mid = MidiFile()\n",
    "#     track = MidiTrack()\n",
    "#     mid.tracks.append(track)\n",
    "#     track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(BPM)))\n",
    "#     for tones in song:\n",
    "#         which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "#         if len(which_tone) == 0:\n",
    "#             track.append(Message('note_on', note=0, velocity=0, time=0))\n",
    "#             track.append(Message('note_off', note=0, time=interval))\n",
    "#         else:\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_on', note=int(which), velocity=velocity, time=0))\n",
    "#             for which in which_tone:\n",
    "#                 track.append(Message('note_off', note=int(which), time=interval))\n",
    "#     mid.save(os.path.join(path, name))\n",
    "\n",
    "def save_as_midi(song, path=\"\", name=\"default.mid\", BPM = 120, velocity = 100):\n",
    "    pm = pretty_midi.PrettyMIDI(resolution=960, initial_tempo=BPM) #pretty_midiオブジェクトを作ります\n",
    "    instrument = pretty_midi.Instrument(0) #instrumentはトラックみたいなものです。\n",
    "    for i,tones in enumerate(song):\n",
    "        which_tone = (tones == 1).nonzero().reshape(-1)\n",
    "        print(which_tone)\n",
    "        if len(which_tone) == 0:\n",
    "            note = pretty_midi.Note(velocity=0, pitch=0, start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "            instrument.notes.append(note)\n",
    "        else:\n",
    "            for which in which_tone:\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=int(which), start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\n",
    "                instrument.notes.append(note)\n",
    "                print(\"DONE\")\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(os.path.join(path, name)) #midiファイルを書き込みます。\n",
    "\n",
    "\n",
    "def midi_to_wav(midi_name, midi_path=\"\", wav_name = None, wav_path=\"\", rate=44100):\n",
    "    if wav_name == None:\n",
    "        wav_name = os.path.splitext(midi_name)[0]+ \".wav\"\n",
    "        print(wav_name)\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_name) #midiファイルを読み込みます\n",
    "    data = np.array(midi_data.synthesize()*1e5, dtype = \"int16\")\n",
    "    write(os.path.join(wav_path, wav_name), rate, data )"
   ]
  },
  {
   "source": [
    "## generate X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate X\n",
    "def generate_Xs(dmm, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths):\n",
    "    songs_dic = {}\n",
    "    generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\n",
    "    for i, song in enumerate(generated_mini_batch):\n",
    "        tones_container = []\n",
    "        for time in range(mini_batch_seq_lengths[i]):\n",
    "            # print(song[time])\n",
    "            p = dist.Bernoulli(probs=song[time])\n",
    "            tone = p.sample()\n",
    "            tones_container.append(tone)\n",
    "        tones_container = torch.stack(tones_container)\n",
    "        songs_dic.update([(\"song%02d\"%(i), tones_container)])\n",
    "    return songs_dic"
   ]
  },
  {
   "source": [
    "## Listen to MIDI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_midi(name, path=\"\"):\n",
    "    ports = mido.get_output_names()\n",
    "    print(\"START\")\n",
    "    with mido.open_output(ports[0]) as outport:\n",
    "        for msg in mido.MidiFile(os.path.join(path,name)):\n",
    "            time.sleep(msg.time)\n",
    "            if not msg.is_meta:\n",
    "                # print(outport, msg)\n",
    "                outport.send(msg)\n",
    "    print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ドドド、レレレ、ミミミ、ドレミ\n",
    "def easyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(5):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(20+i*10)] = 1\n",
    "    for i in range(5,8):\n",
    "        training_data_sequences[i][0][int(110-i*10)  ] = 1\n",
    "        training_data_sequences[i][1][int(110-i*10)+2] = 1\n",
    "        training_data_sequences[i][2][int(110-i*10)+4] = 1\n",
    "        training_data_sequences[i][3][int(110-i*10)+5] = 1\n",
    "        training_data_sequences[i][4][int(110-i*10)+7] = 1\n",
    "        training_data_sequences[i][5][int(110-i*10)+9] = 1\n",
    "        training_data_sequences[i][6][int(110-i*10)+11] = 1\n",
    "        training_data_sequences[i][7][int(110-i*10)+12] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、レレレ\n",
    "def superEasyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(30+i*5)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、ドドド、ドドド\n",
    "def easiestTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(70)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## 長さ最長129、例えば長さが60のやつは61~129はすべて0データ\n",
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "training_seq_lengths = data['train']['sequence_lengths']\n",
    "training_data_sequences = data['train']['sequences']\n",
    "\n",
    "training_seq_lengths, training_data_sequences = superEasyTones()\n",
    "# training_seq_lengths, training_data_sequences = easyTones()\n",
    "# training_seq_lengths, training_data_sequences = easiestTones()\n",
    "\n",
    "## 長さ最長129、例えば長さが60のやつは61~129はすべて0データ\n",
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "training_seq_lengths = data['train']['sequence_lengths']\n",
    "training_data_sequences = data['train']['sequences']\n",
    "\n",
    "\n",
    "N_train_data = len(training_seq_lengths)\n",
    "shuffled_indices = torch.randperm(N_train_data)\n",
    "mini_batch_indices = shuffled_indices\n",
    "mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "                = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                                        training_seq_lengths, cuda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.join(\"saveData\", \"20210124_11_43\")\n",
    "# DMM_dics = torch.load(os.path.join(path,\"DMM_dic\"))\n",
    "DMM_dics = torch.load(\"Model\")\n",
    "# DMM_dic = DMM_dics[\"DMM_dic\"]\n",
    "# WN_dic = DMM_dics[\"WGAN_Network_dic\"]\n",
    "\n",
    "dmm = DMM(use_cuda=False, rnn_check=False, rpt=True)\n",
    "# WN = WGAN_network()\n",
    "# WN.load_state_dict(WN_dic())\n",
    "# W = WassersteinLoss(WN, N_loops=10, lr=0.00001)\n",
    "\n",
    "dmm.load_state_dict(DMM_dics)\n",
    "generated_mini_batch = dmm(mini_batch, mini_batch_reversed, mini_batch_mask,  mini_batch_seq_lengths)\n",
    "songs = generate_Xs(dmm, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([30, 35])\nDONE\nDONE\ntensor([35, 40, 50])\nDONE\nDONE\nDONE\ntensor([30, 35, 55, 60])\nDONE\nDONE\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([65])\nDONE\ntensor([60, 70])\nDONE\nDONE\ntensor([30, 35])\nDONE\nDONE\ntensor([45, 60, 75])\nDONE\nDONE\nDONE\ntensor([40, 50])\nDONE\nDONE\ntensor([60, 75])\nDONE\nDONE\ntensor([50, 60])\nDONE\nDONE\ntensor([55])\nDONE\ntensor([], dtype=torch.int64)\ntensor([45, 60, 70])\nDONE\nDONE\nDONE\ntensor([40])\nDONE\ntensor([65])\nDONE\ntensor([35, 55])\nDONE\nDONE\ntensor([35, 70])\nDONE\nDONE\ntensor([35, 65, 75])\nDONE\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([35, 40, 50, 65, 70])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([40, 45, 60])\nDONE\nDONE\nDONE\ntensor([35, 50])\nDONE\nDONE\ntensor([65])\nDONE\ntensor([70])\nDONE\ntensor([65])\nDONE\ntensor([60, 70, 75])\nDONE\nDONE\nDONE\ntensor([60, 75])\nDONE\nDONE\ntensor([60, 70])\nDONE\nDONE\ntensor([43, 55, 60, 65, 70])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([35, 40, 45, 60, 65])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([35])\nDONE\ntensor([35, 65, 75])\nDONE\nDONE\nDONE\ntensor([70])\nDONE\ntensor([60, 70])\nDONE\nDONE\ntensor([30, 50, 65])\nDONE\nDONE\nDONE\ntensor([30, 55, 70, 74])\nDONE\nDONE\nDONE\nDONE\ntensor([45])\nDONE\ntensor([35])\nDONE\ntensor([15, 30, 75])\nDONE\nDONE\nDONE\ntensor([35, 50, 55])\nDONE\nDONE\nDONE\ntensor([65, 70, 75])\nDONE\nDONE\nDONE\ntensor([35, 40])\nDONE\nDONE\ntensor([55])\nDONE\ntensor([35])\nDONE\ntensor([30, 55, 75])\nDONE\nDONE\nDONE\ntensor([30, 70])\nDONE\nDONE\ntensor([30, 35, 75])\nDONE\nDONE\nDONE\ntensor([40])\nDONE\ntensor([70])\nDONE\ntensor([40, 45])\nDONE\nDONE\ntensor([30, 35, 60, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([65])\nDONE\ntensor([], dtype=torch.int64)\ntensor([55, 60, 65])\nDONE\nDONE\nDONE\ntensor([50, 60])\nDONE\nDONE\ntensor([35])\nDONE\ntensor([30, 55])\nDONE\nDONE\ntensor([35, 55, 60])\nDONE\nDONE\nDONE\ntensor([30, 55, 70])\nDONE\nDONE\nDONE\ntensor([40, 55])\nDONE\nDONE\ntensor([35, 60])\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([35])\nDONE\ntensor([30])\nDONE\ntensor([40])\nDONE\ntensor([], dtype=torch.int64)\ntensor([], dtype=torch.int64)\ntensor([40])\nDONE\ntensor([35, 65, 70, 75])\nDONE\nDONE\nDONE\nDONE\ntensor([55, 70])\nDONE\nDONE\ntensor([30, 50, 60])\nDONE\nDONE\nDONE\ntensor([45, 55, 60])\nDONE\nDONE\nDONE\ntensor([45, 50, 55, 65, 70])\nDONE\nDONE\nDONE\nDONE\nDONE\ntensor([40])\nDONE\ntensor([45, 50, 65])\nDONE\nDONE\nDONE\ntensor([30, 65])\nDONE\nDONE\ntensor([60])\nDONE\ntensor([36, 55])\nDONE\nDONE\ntensor([35, 50, 75])\nDONE\nDONE\nDONE\ntensor([50, 70, 75])\nDONE\nDONE\nDONE\ntensor([35, 70])\nDONE\nDONE\ntensor([75])\nDONE\ntensor([35, 55])\nDONE\nDONE\ntensor([45, 65])\nDONE\nDONE\ntensor([45])\nDONE\ntensor([45, 60])\nDONE\nDONE\ntensor([35, 50, 75])\nDONE\nDONE\nDONE\ntensor([45, 70])\nDONE\nDONE\ntensor([45, 50])\nDONE\nDONE\ntensor([50, 55, 70, 75])\nDONE\nDONE\nDONE\nDONE\ntensor([30, 60, 70])\nDONE\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([70])\nDONE\ntensor([40, 75])\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([30, 60, 75])\nDONE\nDONE\nDONE\ntensor([60])\nDONE\ntensor([40, 65])\nDONE\nDONE\ntensor([60])\nDONE\ntensor([65])\nDONE\ntensor([40, 55, 60, 70])\nDONE\nDONE\nDONE\nDONE\ntensor([55, 65])\nDONE\nDONE\ntensor([60])\nDONE\ntensor([45, 65])\nDONE\nDONE\ntensor([65, 70, 75])\nDONE\nDONE\nDONE\ntensor([35, 55])\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([45, 60])\nDONE\nDONE\ntensor([50, 55])\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([], dtype=torch.int64)\ntensor([40])\nDONE\ntensor([50, 60])\nDONE\nDONE\ntensor([60])\nDONE\ntensor([40])\nDONE\ntensor([30, 55, 70, 75])\nDONE\nDONE\nDONE\nDONE\ntensor([40, 60])\nDONE\nDONE\ntensor([], dtype=torch.int64)\ntensor([], dtype=torch.int64)\ntensor([30, 55, 70, 75])\nDONE\nDONE\nDONE\nDONE\ntensor([50, 75])\nDONE\nDONE\ntensor([30, 45, 60])\nDONE\nDONE\nDONE\ntensor([45, 55])\nDONE\nDONE\ntensor([45, 50, 70])\nDONE\nDONE\nDONE\ntensor([40, 65, 70])\nDONE\nDONE\nDONE\ntensor([45, 70])\nDONE\nDONE\ntensor([45, 55, 75])\nDONE\nDONE\nDONE\ntensor([39, 51, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([46, 49, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 56, 65])\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 51, 60, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 51, 60, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([37, 49, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 49, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([47, 50, 55, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([45, 48, 53, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([45, 48, 53, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 51, 57, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([43, 50, 59, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 63])\nDONE\nDONE\nDONE\ntensor([41, 44, 53, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 51, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([34, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 51, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([46, 49, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 56, 65])\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 51, 60, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 51, 60, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([37, 49, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 49, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([47, 50, 55, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([45, 48, 53, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([45, 48, 53, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 51, 57, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([43, 50, 59, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 60, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 63])\nDONE\nDONE\nDONE\ntensor([41, 44, 53, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 51, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([34, 50, 58, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([34, 46, 53, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([43, 55, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 56, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([34, 46, 53, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([44, 53, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([43, 55, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 56, 58, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 58, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 55, 63])\nDONE\nDONE\nDONE\ntensor([39, 51, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([46, 49, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 56, 65])\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 56, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([40, 55, 60, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 64])\nDONE\nDONE\nDONE\ntensor([36, 48, 55, 64])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 51, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([46, 49, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 56, 65])\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 56, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 50, 58, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([51, 58, 67])\nDONE\nDONE\nDONE\ntensor([40, 55, 60, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 49, 58, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 55, 64])\nDONE\nDONE\nDONE\ntensor([36, 48, 55, 64])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([47, 50, 55, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([48, 51, 55, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([46, 55, 63])\nDONE\nDONE\nDONE\ntensor([44, 48, 53, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([43, 46, 52, 67])\nDONE\nDONE\nDONE\nDONE\ntensor([41, 48, 53, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([39, 48, 55, 68])\nDONE\nDONE\nDONE\nDONE\ntensor([38, 47, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([36, 48, 56, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([35, 50, 55, 65])\nDONE\nDONE\nDONE\nDONE\ntensor([36, 48, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([33, 48, 53, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([34, 46, 53, 62])\nDONE\nDONE\nDONE\nDONE\ntensor([27, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([27, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([27, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\ntensor([27, 46, 55, 63])\nDONE\nDONE\nDONE\nDONE\n"
     ]
    }
   ],
   "source": [
    "No = 0\n",
    "song = songs[\"song%02d\"%No]\n",
    "lengthG = len(song)\n",
    "save_as_midi(song=song, name=\"Gen.mid\")\n",
    "\n",
    "song = mini_batch[No]\n",
    "lengthT = mini_batch_seq_lengths[No]\n",
    "save_as_midi(song=song, name=\"Tra.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'rtmidi' has no attribute 'API_UNSPECIFIED'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c27aef5f426f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# path = os.path.join(\"saveData\", \"20210115_12_21\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# epoch_number = 20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tra.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gen.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-0de5f9f72f83>\u001b[0m in \u001b[0;36mlisten_midi\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlisten_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"START\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutport\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/backend.py\u001b[0m in \u001b[0;36mget_output_names\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;34m\"\"\"Return a sorted list of all output port names.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/backend.py\u001b[0m in \u001b[0;36m_get_devices\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_devices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/rtmidi.py\u001b[0m in \u001b[0;36mget_devices\u001b[0;34m(api, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mrtapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_api_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiIn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mido/backends/rtmidi.py\u001b[0m in \u001b[0;36m_get_api_id\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_api_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrtmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI_UNSPECIFIED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'rtmidi' has no attribute 'API_UNSPECIFIED'"
     ]
    }
   ],
   "source": [
    "# # path = os.path.join(\"saveData\", \"20210108_22_40\")\n",
    "# path = os.path.join(\"saveData\", \"20210115_12_21\")\n",
    "# epoch_number = 20000\n",
    "listen_midi(\"Tra.mid\")\n",
    "listen_midi(\"Gen.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import argparse\r\n",
    "import logging\r\n",
    "import time\r\n",
    "import random\r\n",
    "import datetime\r\n",
    "import tqdm\r\n",
    "from os.path import exists\r\n",
    "import os\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import pyro\r\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\r\n",
    "import pyro.distributions as dist\r\n",
    "import pyro.poutine as poutine\r\n",
    "from pyro.distributions import TransformedDistribution\r\n",
    "from pyro.distributions.transforms import affine_autoregressive\r\n",
    "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceEnum_ELBO, TraceTMC_ELBO, config_enumerate\r\n",
    "from pyro.optim import ClippedAdam\r\n",
    "\r\n",
    "import ot\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import mido\r\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage\r\n",
    "\r\n",
    "from midi2audio import FluidSynth\r\n",
    "\r\n",
    "import pretty_midi\r\n",
    "from scipy.io import wavfile\r\n",
    "\r\n",
    "import musics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class and Def"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Emitter(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Parameterizes the bernoulli observation likelihood `p(x_t | z_t)`\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, input_dim, z_dim, emission_dim, use_cuda=False):\r\n",
    "        super().__init__()\r\n",
    "        self.input_dim = input_dim\r\n",
    "        self.use_cuda = use_cuda\r\n",
    "        # initialize the three linear transformations used in the neural network\r\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim)\r\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim)\r\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim)\r\n",
    "        # initialize the two non-linearities used in the neural network\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "\r\n",
    "    def forward(self, z_t):\r\n",
    "        \"\"\"\r\n",
    "        Given the latent z at a particular time step t we return the vector of\r\n",
    "        probabilities `ps` that parameterizes the bernoulli distribution `p(x_t|z_t)`\r\n",
    "        \"\"\"\r\n",
    "        h1 = self.relu(self.lin_z_to_hidden(z_t))\r\n",
    "        h2 = self.relu(self.lin_hidden_to_hidden(h1))\r\n",
    "        if self.input_dim == 1:\r\n",
    "            x = self.lin_hidden_to_input(h2)\r\n",
    "        else:\r\n",
    "            ps = torch.sigmoid(self.lin_hidden_to_input(h2))\r\n",
    "\r\n",
    "            #Reparameterization Trick\r\n",
    "            if self.use_cuda: \r\n",
    "                eps = torch.rand(self.input_dim).cuda()\r\n",
    "            else : eps = torch.rand(self.input_dim)\r\n",
    "            # assert len(emission_probs_t) == 88\r\n",
    "            appxm = torch.log(eps + 1e-20) - torch.log(1-eps + 1e-20) + torch.log(ps + 1e-20) - torch.log(1-ps + 1e-20)\r\n",
    "            # appxm = torch.log(eps) - torch.log(1-eps) + torch.log(x) - torch.log(1-x)\r\n",
    "            x = torch.sigmoid(appxm)\r\n",
    "        return x\r\n",
    "\r\n",
    "class GatedTransition(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Parameterizes the gaussian latent transition probability `p(z_t | z_{t-1})`\r\n",
    "    See section 5 in the reference for comparison.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, z_dim, transition_dim):\r\n",
    "        super().__init__()\r\n",
    "        # initialize the six linear transformations used in the neural network\r\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim)\r\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim)\r\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim)\r\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim)\r\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim)\r\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim)\r\n",
    "        # modify the default initialization of lin_z_to_loc\r\n",
    "        # so that it's starts out as the identity function\r\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim)\r\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim)\r\n",
    "        # initialize the three non-linearities used in the neural network\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.softplus = nn.Softplus()\r\n",
    "\r\n",
    "    def forward(self, z_t_1):\r\n",
    "        \"\"\"\r\n",
    "        Given the latent `z_{t-1}` corresponding to the time step t-1\r\n",
    "        we return the mean and scale vectors that parameterize the\r\n",
    "        (diagonal) gaussian distribution `p(z_t | z_{t-1})`\r\n",
    "        \"\"\"\r\n",
    "        # compute the gating function\r\n",
    "        _gate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\r\n",
    "        gate = torch.sigmoid(self.lin_gate_hidden_to_z(_gate))\r\n",
    "        # compute the 'proposed mean'\r\n",
    "        _proposed_mean = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\r\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\r\n",
    "        # assemble the actual mean used to sample z_t, which mixes a linear transformation\r\n",
    "        # of z_{t-1} with the proposed mean modulated by the gating function\r\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\r\n",
    "        # compute the scale used to sample z_t, using the proposed mean from\r\n",
    "        # above as input the softplus ensures that scale is positive\r\n",
    "        scale = self.softplus(self.lin_sig(self.relu(proposed_mean)))\r\n",
    "        # return loc, scale which can be fed into Normal\r\n",
    "        return loc, scale\r\n",
    "\r\n",
    "class Combiner(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Parameterizes `q(z_t | z_{t-1}, x_{t:T})`, which is the basic building block\r\n",
    "    of the guide (i.e. the variational distribution). The dependence on `x_{t:T}` is\r\n",
    "    through the hidden state of the RNN (see the PyTorch module `rnn` below)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, z_dim, rnn_dim):\r\n",
    "        super().__init__()\r\n",
    "        # initialize the three linear transformations used in the neural network\r\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim)\r\n",
    "        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\r\n",
    "        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\r\n",
    "        # initialize the two non-linearities used in the neural network\r\n",
    "        self.tanh = nn.Tanh()\r\n",
    "        self.softplus = nn.Softplus()\r\n",
    "\r\n",
    "    def forward(self, z_t_1, h_rnn):\r\n",
    "        \"\"\"\r\n",
    "        Given the latent z at at a particular time step t-1 as well as the hidden\r\n",
    "        state of the RNN `h(x_{t:T})` we return the mean and scale vectors that\r\n",
    "        parameterize the (diagonal) gaussian distribution `q(z_t | z_{t-1}, x_{t:T})`\r\n",
    "        \"\"\"\r\n",
    "        # combine the rnn hidden state with a transformed version of z_t_1\r\n",
    "        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)\r\n",
    "        # use the combined hidden state to compute the mean used to sample z_t\r\n",
    "        loc = self.lin_hidden_to_loc(h_combined)\r\n",
    "        # use the combined hidden state to compute the scale used to sample z_t\r\n",
    "        scale = self.softplus(self.lin_hidden_to_scale(h_combined))\r\n",
    "        # return loc, scale which can be fed into Normal\r\n",
    "        return loc, scale\r\n",
    "\r\n",
    "class Encoder(nn.Module):\r\n",
    "    def __init__(self, input_dim=88, z_dim=100,rnn_dim=60, num_layers=1, rnn_dropout_rate=0.1,num_iafs=0, iaf_dim=50, use_cuda=False, rnn_check=False):\r\n",
    "        super().__init__()\r\n",
    "        # instantiate PyTorch modules used in the model and guide below\r\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\r\n",
    "        # dropout just takes effect on inner layers of rnn\r\n",
    "        rnn_dropout_rate = 0. if num_layers == 1 else rnn_dropout_rate\r\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=rnn_dim, nonlinearity='relu',\r\n",
    "                          batch_first=True, bidirectional=False, num_layers=num_layers,\r\n",
    "                          dropout=rnn_dropout_rate)\r\n",
    "\r\n",
    "        # if we're using normalizing flows, instantiate those too\r\n",
    "        # self.iafs = [affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)]\r\n",
    "        # self.iafs_modules = nn.ModuleList(self.iafs)\r\n",
    "\r\n",
    "        # define a (trainable) parameters z_0 and z_q_0 that help define the probability\r\n",
    "        # distributions p(z_1) and q(z_1)\r\n",
    "        # (since for t = 1 there are no previous latents to condition on)\r\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\r\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\r\n",
    "        # define a (trainable) parameter for the initial hidden state of the rnn\r\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim))\r\n",
    "\r\n",
    "        self.use_cuda = use_cuda\r\n",
    "        # if on gpu cuda-ize all PyTorch (sub)modules\r\n",
    "        if use_cuda:\r\n",
    "            self.cuda()\r\n",
    "\r\n",
    "        self.rnn_check = rnn_check\r\n",
    "\r\n",
    "    def forward(self, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths, annealing_factor=1.0):\r\n",
    "\r\n",
    "        # this is the number of time steps we need to process in the mini-batch\r\n",
    "        T_max = mini_batch.size(1)\r\n",
    "\r\n",
    "        # if on gpu we need the fully broadcast view of the rnn initial state\r\n",
    "        # to be in contiguous gpu memory\r\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0), self.rnn.hidden_size).contiguous()\r\n",
    "        # if any(torch.isnan(h_0_contig.reshape(-1))):\r\n",
    "        #     for param in self.rnn.parameters():\r\n",
    "        #         print(param)\r\n",
    "        #     assert False\r\n",
    "        # push the observed x's through the rnn;\r\n",
    "        # rnn_output contains the hidden state at each time step\r\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\r\n",
    "        # if True:\r\n",
    "        #     if any(torch.isnan(rnn_output.data.reshape(-1))):\r\n",
    "        #         assert False\r\n",
    "\r\n",
    "        # reverse the time-ordering in the hidden state and un-pack it\r\n",
    "        rnn_output = poly.pad_and_reverse(rnn_output, mini_batch_seq_lengths)\r\n",
    "\r\n",
    "        # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)\r\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\r\n",
    "        # if any(torch.isnan(z_prev.reshape(-1))):\r\n",
    "        #     print(\"z_prev\")\r\n",
    "\r\n",
    "        z_container = []\r\n",
    "        z_loc_container = []\r\n",
    "        z_scale_container = []\r\n",
    "        for t in range(1,T_max+1):\r\n",
    "            # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\r\n",
    "            z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\r\n",
    "\r\n",
    "            # Reparameterization Trick\r\n",
    "            if self.use_cuda:\r\n",
    "                eps = torch.randn(z_loc.size()).cuda()\r\n",
    "            else: eps = torch.randn(z_loc.size())\r\n",
    "            z_t = z_loc + z_scale * eps\r\n",
    "\r\n",
    "            # the latent sampled at this time step will be conditioned upon\r\n",
    "            # in the next time step so keep track of it\r\n",
    "            z_prev = z_t\r\n",
    "            z_container.append(z_t)\r\n",
    "            z_loc_container.append(z_loc)\r\n",
    "            z_scale_container.append(z_scale)\r\n",
    "        \r\n",
    "        z_container = torch.stack(z_container)\r\n",
    "        z_loc_container = torch.stack(z_loc_container)\r\n",
    "        z_scale_container = torch.stack(z_scale_container)\r\n",
    "        return z_container.transpose(0,1), z_loc_container.transpose(0,1), z_scale_container.transpose(0,1)\r\n",
    "\r\n",
    "class Prior(nn.Module):\r\n",
    "    def __init__(self, z_dim=100, transition_dim=200, use_cuda=False):\r\n",
    "        super().__init__()\r\n",
    "        # instantiate PyTorch modules used in the model and guide below\r\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\r\n",
    "\r\n",
    "        # define a (trainable) parameters z_0 and z_q_0 that help define the probability\r\n",
    "        # distributions p(z_1) and q(z_1)\r\n",
    "        # (since for t = 1 there are no previous latents to condition on)\r\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\r\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\r\n",
    "\r\n",
    "        self.use_cuda = use_cuda\r\n",
    "        # if on gpu cuda-ize all PyTorch (sub)modules\r\n",
    "\r\n",
    "    def forward(self, length, N_generate):\r\n",
    "\r\n",
    "        # this is the number of time steps we need to process in the mini-batch\r\n",
    "        T_max = length\r\n",
    "\r\n",
    "        # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)\r\n",
    "        z_prev = self.z_q_0.expand(N_generate, self.z_q_0.size(0))\r\n",
    "        # if any(torch.isnan(z_prev.reshape(-1))):\r\n",
    "        #     print(\"z_prev\")\r\n",
    "\r\n",
    "        z_container = []\r\n",
    "        z_loc_container = []\r\n",
    "        z_scale_container = []\r\n",
    "        for t in range(1,T_max+1):\r\n",
    "            # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\r\n",
    "            z_loc, z_scale = self.trans(z_prev)\r\n",
    "\r\n",
    "            # Reparameterization Trick\r\n",
    "            if self.use_cuda:\r\n",
    "                eps = torch.randn(z_loc.size()).cuda()\r\n",
    "            else: eps = torch.randn(z_loc.size())\r\n",
    "            z_t = z_loc + z_scale * eps\r\n",
    "\r\n",
    "            z_prev = z_t\r\n",
    "            z_container.append(z_t)\r\n",
    "            z_loc_container.append(z_loc)\r\n",
    "            z_scale_container.append(z_scale)\r\n",
    "        \r\n",
    "        z_container = torch.stack(z_container)\r\n",
    "        z_loc_container = torch.stack(z_loc_container)\r\n",
    "        z_scale_container = torch.stack(z_scale_container)\r\n",
    "        return z_container.transpose(0,1), z_loc_container.transpose(0,1), z_scale_container.transpose(0,1)\r\n",
    "\r\n",
    "\r\n",
    "def multi_normal_prob(loc,scale,x):\r\n",
    "    # locは平均, scaleは共分散行列, xはサンプルとする。\r\n",
    "    pi_2_d = torch.tensor(np.sqrt((np.pi * 2) ** loc.size(-1)))\r\n",
    "    det = torch.sum(scale, dim=2)\r\n",
    "    mom = torch.sqrt(det) * pi_2_d\r\n",
    "    exp_arg = -0.5 * torch.sum((x-loc) * (x-loc) / scale, dim=2)\r\n",
    "    return torch.exp(exp_arg) / mom\r\n",
    "\r\n",
    "def D_KL(p_loc, q_loc, p_scale, q_scale):\r\n",
    "    # locは平均, scaleは共分散行列とする。\r\n",
    "    # size = [曲数、拍数、88鍵]\r\n",
    "    # Determinant of Covariance Matrix\r\n",
    "    det_p_scale = torch.prod(p_scale, dim=2)\r\n",
    "    det_q_scale = torch.prod(q_scale, dim=2)\r\n",
    "    # Dimension of Maltivariate Normal Distribution\r\n",
    "    dim = p_loc.size(-1)\r\n",
    "    beats = p_loc.size(1)\r\n",
    "    songs = p_loc.size(0)\r\n",
    "    # Trace of (\\Sigma_q^{-1} \\Sigma_p)\r\n",
    "    trace = torch.sum(p_scale/q_scale, dim = 2)\r\n",
    "    # (loc_q - loc_p)^T \\Sigma_q (loc_q - loc_p)\r\n",
    "    niji = torch.sum((q_loc-p_loc)*(q_loc-p_loc)/q_scale, dim=2)\r\n",
    "    # KL-divergence\r\n",
    "    KL = 0.5 *(torch.log(det_q_scale) - torch.log(det_p_scale) - dim + trace + niji)\r\n",
    "    return KL.sum() / (beats * songs)\r\n",
    "\r\n",
    "def D_Wass(p_loc, q_loc, p_scale, q_scale):\r\n",
    "    # locは平均, scaleは共分散行列とする。\r\n",
    "    # size = [曲数、拍数、88鍵]\r\n",
    "    beats = p_loc.size(1)\r\n",
    "    songs = p_loc.size(0)\r\n",
    "    # Determinant of Covariance Matrix\r\n",
    "    norm_2 = torch.sum((p_loc - q_loc)*(p_loc - q_loc), dim=2)\r\n",
    "    # Dimension of Maltivariate Normal Distribution\r\n",
    "    trace_p_scale = torch.sum(p_scale, dim=2)\r\n",
    "    trace_q_scale = torch.sum(q_scale, dim=2)\r\n",
    "    trace = torch.sum(torch.sqrt(p_scale*q_scale), dim=2)\r\n",
    "    # KL-divergence\r\n",
    "    Wass = torch.sqrt(norm_2 + trace_p_scale + trace_q_scale - 2 * trace)\r\n",
    "    return Wass.sum() / (beats * songs)\r\n",
    "    \r\n",
    "def saveGraph(loss_list, sub_error_list,now):\r\n",
    "        FS = 10\r\n",
    "        fig = plt.figure()\r\n",
    "        plt.rcParams[\"font.size\"] = FS\r\n",
    "        plt.plot(loss_list, label=\"LOSS\")\r\n",
    "        plt.plot(sub_error_list, label=\"Reconstruction Error\")\r\n",
    "        plt.ylim(bottom=0)\r\n",
    "        plt.title(\"Loss\")\r\n",
    "        plt.xlabel(\"epoch\", fontsize=FS)\r\n",
    "        plt.ylabel(\"loss\", fontsize=FS)\r\n",
    "        plt.legend()\r\n",
    "        fig.savefig(os.path.join(\"saveData\", now, \"LOSS.png\"))\r\n",
    "\r\n",
    "    \r\n",
    "def saveReconSinGraph(train_data, recon_data, length, path, number):\r\n",
    "    FS = 10\r\n",
    "    fig = plt.figure()\r\n",
    "    plt.rcParams[\"font.size\"] = FS\r\n",
    "    x = np.linspace(0, 2*np.pi, length)\r\n",
    "    plt.plot(x, train_data, label=\"Training data\")\r\n",
    "    plt.plot(x, recon_data.detach().numpy(), label=\"Reconstructed data\")\r\n",
    "    # plt.ylim(bottom=0)\r\n",
    "    plt.title(\"Sin Curves\")\r\n",
    "    plt.ylim(top=3, bottom=-3)\r\n",
    "    plt.xlabel(\"time\", fontsize=FS)\r\n",
    "    plt.ylabel(\"y\", fontsize=FS)\r\n",
    "    plt.legend()\r\n",
    "    fig.savefig(os.path.join(path, \"Reconstruction\"+str(number)+\".png\"))\r\n",
    "\r\n",
    "def saveGeneSinGraph(gene_data, length, path, number):\r\n",
    "    FS = 10\r\n",
    "    fig = plt.figure()\r\n",
    "    plt.rcParams[\"font.size\"] = FS\r\n",
    "    x = np.linspace(0, 2*np.pi, length)\r\n",
    "    plt.plot(x, gene_data.detach().numpy(), label=\"Generated data\")\r\n",
    "    # plt.ylim(bottom=0)\r\n",
    "    plt.title(\"Sin Curves\")\r\n",
    "    plt.ylim(top=3, bottom=-3)\r\n",
    "    plt.xlabel(\"time\", fontsize=FS)\r\n",
    "    plt.ylabel(\"y\", fontsize=FS)\r\n",
    "    plt.legend()\r\n",
    "    fig.savefig(os.path.join(path, \"Generation\"+str(number)+\".png\"))\r\n",
    "\r\n",
    "## This func is for save generatedTones and trainingTones as MIDI\r\n",
    "def save_as_midi(song, path=\"\", name=\"default.mid\", BPM = 120, velocity = 100):\r\n",
    "    pm = pretty_midi.PrettyMIDI(resolution=960, initial_tempo=BPM) #pretty_midiオブジェクトを作ります\r\n",
    "    instrument = pretty_midi.Instrument(0) #instrumentはトラックみたいなものです。\r\n",
    "    for i,tones in enumerate(song):\r\n",
    "        which_tone = torch.nonzero((tones == 1), as_tuple=False).reshape(-1)\r\n",
    "        if len(which_tone) == 0:\r\n",
    "            note = pretty_midi.Note(velocity=0, pitch=0, start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\r\n",
    "            instrument.notes.append(note)\r\n",
    "        else:\r\n",
    "            for which in which_tone:\r\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=int(which), start=i, end=i+1) #noteはNoteOnEventとNoteOffEventに相当します。\r\n",
    "                instrument.notes.append(note)\r\n",
    "    pm.instruments.append(instrument)\r\n",
    "    pm.write(os.path.join(path, name)) #midiファイルを書き込みます。\r\n",
    "\r\n",
    "# generate Xs\r\n",
    "def generate_Xs(batch_data):\r\n",
    "    songs_list = []\r\n",
    "    for i, song in enumerate(batch_data):\r\n",
    "        tones_container = []\r\n",
    "        for time in range(batch_data.size(1)):\r\n",
    "            p = dist.Bernoulli(probs=song[time])\r\n",
    "            tone = p.sample()\r\n",
    "            tones_container.append(tone)\r\n",
    "        tones_container = torch.stack(tones_container)\r\n",
    "        songs_list.append(tones_container)\r\n",
    "    return songs_list\r\n",
    "\r\n",
    "def saveSongs(songs_list, mini_batch, N_songs, path):\r\n",
    "    # print(len(songs_list[0][0]))\r\n",
    "    if len(songs_list) != len(mini_batch):\r\n",
    "        assert False\r\n",
    "    if N_songs <= len(songs_list):\r\n",
    "        song_No = random.sample(range(len(songs_list)), k=N_songs)\r\n",
    "    else :\r\n",
    "        song_No = random.sample(range(len(songs_list)), k=len(songs_list))\r\n",
    "    for i, Number in enumerate(song_No):\r\n",
    "        save_as_midi(song=songs_list[Number], path=path, name=\"No%d_Gene.midi\"%i)\r\n",
    "        save_as_midi(song=mini_batch[Number], path=path, name=\"No%d_Tran.midi\"%i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Arguments\r\n",
    "cuda = False\r\n",
    "N_songs = 2\r\n",
    "length = 20\r\n",
    "mini_batch_size = 20\r\n",
    "z_dim = 100\r\n",
    "rnn_dim = 200\r\n",
    "transition_dim = 200\r\n",
    "emission_dim =100\r\n",
    "\r\n",
    "encoder = Encoder(input_dim=1, z_dim=z_dim, rnn_dim=rnn_dim)\r\n",
    "prior = Prior(z_dim=z_dim, transition_dim=transition_dim, use_cuda=cuda)\r\n",
    "decoder = Emitter(input_dim=1, z_dim=z_dim, emission_dim=emission_dim, use_cuda=cuda)\r\n",
    "\r\n",
    "params = list(encoder.parameters()) + list(prior.parameters()) + list(decoder.parameters()) \r\n",
    "optimizer = optim.Adam(params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "date = \"2021\" + \"0831\" + \"_\" + \"14_49\"\r\n",
    "path = os.path.join(\"saveData\", date)\r\n",
    "DMM_dics = torch.load(os.path.join(path,\"DMM_dic\"))\r\n",
    "# DMM_dics = torch.load(os.path.join(path,\"fail_DMM_dic\"))\r\n",
    "encoder_dic = DMM_dics[\"Encoder_dic\"]()\r\n",
    "prior_dic = DMM_dics[\"Prior_dic\"]()\r\n",
    "decoder_dic = DMM_dics[\"Emitter_dic\"]()\r\n",
    "optimizer_dic = DMM_dics[\"optimizer\"].state_dict()\r\n",
    "training_data_sequences = DMM_dics[\"mini_batch\"]\r\n",
    "\r\n",
    "encoder.load_state_dict(encoder_dic)\r\n",
    "prior.load_state_dict(prior_dic)\r\n",
    "decoder.load_state_dict(decoder_dic)\r\n",
    "optimizer.load_state_dict(optimizer_dic)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "which_mini_batch = 0\r\n",
    "training_seq_lengths = torch.tensor([length]*N_songs)\r\n",
    "data_dim = training_data_sequences.size(-1)\r\n",
    "\r\n",
    "N_train_data = len(training_seq_lengths)\r\n",
    "N_train_time_slices = float(torch.sum(training_seq_lengths))\r\n",
    "N_mini_batches = int(N_train_data / mini_batch_size +\r\n",
    "                int(N_train_data % mini_batch_size > 0))\r\n",
    "shuffled_indices = torch.randperm(N_train_data)\r\n",
    "mini_batch_start = (which_mini_batch * mini_batch_size)\r\n",
    "mini_batch_end = np.min([(which_mini_batch + 1) * mini_batch_size, N_train_data])\r\n",
    "mini_batch_indices = shuffled_indices[mini_batch_start:mini_batch_end]\r\n",
    "\r\n",
    "# grab a fully prepped mini-batch using the helper function in the data loader\r\n",
    "mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\r\n",
    "    = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\r\n",
    "                            training_seq_lengths, cuda=cuda)\r\n",
    "def D_KL(p_loc, q_loc, p_scale, q_scale):\r\n",
    "    # locは平均, scaleは共分散行列とする。\r\n",
    "    # size = [曲数、拍数、88鍵]\r\n",
    "    # Determinant of Covariance Matrix\r\n",
    "    det_p_scale = torch.prod(p_scale, dim=2)\r\n",
    "    det_q_scale = torch.prod(q_scale, dim=2)\r\n",
    "    # Dimension of Maltivariate Normal Distribution\r\n",
    "    dim = p_loc.size(-1)\r\n",
    "    beats = p_loc.size(1)\r\n",
    "    songs = p_loc.size(0)\r\n",
    "    # Trace of (\\Sigma_q^{-1} \\Sigma_p)\r\n",
    "    trace = torch.sum(p_scale/q_scale, dim = 2)\r\n",
    "    # (loc_q - loc_p)^T \\Sigma_q (loc_q - loc_p)\r\n",
    "    niji = torch.sum((q_loc-p_loc)*(q_loc-p_loc)/q_scale, dim=2)\r\n",
    "    # KL-divergence\r\n",
    "    KL = 0.5 *(torch.log(det_q_scale) - torch.log(det_p_scale) - dim + trace + niji)\r\n",
    "    return KL.sum() / (beats * songs)\r\n",
    "\r\n",
    "def D_Wass(p_loc, q_loc, p_scale, q_scale):\r\n",
    "    # locは平均, scaleは共分散行列とする。\r\n",
    "    # size = [曲数、拍数、88鍵]\r\n",
    "    beats = p_loc.size(1)\r\n",
    "    songs = p_loc.size(0)\r\n",
    "    # Determinant of Covariance Matrix\r\n",
    "    norm_2 = torch.sum((p_loc - q_loc)*(p_loc - q_loc), dim=2)\r\n",
    "    # Dimension of Maltivariate Normal Distribution\r\n",
    "    trace_p_scale = torch.sum(p_scale, dim=2)\r\n",
    "    trace_q_scale = torch.sum(q_scale, dim=2)\r\n",
    "    trace = torch.sum(torch.sqrt(p_scale*q_scale), dim=2)\r\n",
    "    # KL-divergence\r\n",
    "    Wass = torch.sqrt(norm_2 + trace_p_scale + trace_q_scale - 2 * trace)\r\n",
    "    return Wass.sum() / (beats * songs)\r\n",
    "    \r\n",
    "# generate mini batch from training mini batch\r\n",
    "# NaN_detect(dmm, epoch, message=\"Before Generate\")\r\n",
    "# with torch.autograd.detect_anomaly():\r\n",
    "#     pos_z, pos_z_loc, pos_z_scale = encoder(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\r\n",
    "#     pri_z, pri_z_loc, pri_z_scale = prior(length = mini_batch.size(1), N_generate= mini_batch.size(0))\r\n",
    "\r\n",
    "#     loss = 0\r\n",
    "#     reconed_x = decoder(pos_z)\r\n",
    "#     # Reconstruction Error\r\n",
    "#     reconstruction_error = torch.norm(mini_batch - reconed_x, dim=2).sum()/mini_batch.size(0)/mini_batch.size(1)/mini_batch.size(2)\r\n",
    "#     # Regularizer (KL-diveergence(pos||pri))\r\n",
    "#     regularizer = D_KL(pos_z_loc, pri_z_loc, pos_z_scale, pri_z_scale)\r\n",
    "\r\n",
    "#     loss += reconstruction_error + 0.11 * regularizer\r\n",
    "\r\n",
    "#     optimizer.zero_grad()\r\n",
    "#     print(reconstruction_error)\r\n",
    "#     print(regularizer)\r\n",
    "#     loss.backward()\r\n",
    "pos_z, pos_z_loc, pos_z_scale = encoder(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\r\n",
    "pri_z, pri_z_loc, pri_z_scale = prior(length = mini_batch.size(1), N_generate= mini_batch.size(0))\r\n",
    "\r\n",
    "loss = 0\r\n",
    "reconed_x = decoder(pos_z)\r\n",
    "# Reconstruction Error\r\n",
    "reconstruction_error = torch.norm(mini_batch - reconed_x, dim=2).sum()/mini_batch.size(0)/mini_batch.size(1)/mini_batch.size(2)\r\n",
    "# Regularizer (KL-diveergence(pos||pri))\r\n",
    "regularizer = D_Wass(pos_z_loc, pri_z_loc, pos_z_scale, pri_z_scale)\r\n",
    "# regularizer = D_Wass(pos_z_loc, pos_z_loc, pos_z_scale, pos_z_scale)\r\n",
    "print(pri_z_loc.size())\r\n",
    "\r\n",
    "loss += reconstruction_error + 0.11 * regularizer\r\n",
    "\r\n",
    "optimizer.zero_grad()\r\n",
    "print(reconstruction_error)\r\n",
    "print(regularizer)\r\n",
    "loss.backward()\r\n",
    "# torch.nn.utils.clip_grad_norm_(params, 1.)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 20, 100])\n",
      "tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "tensor(0.1029, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Kohei Fukuda\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def D_Wass(p_loc, q_loc, p_scale, q_scale):\r\n",
    "    # locは平均, scaleは共分散行列とする。\r\n",
    "    # size = [曲数、拍数、88鍵]\r\n",
    "    beats = p_loc.size(1)\r\n",
    "    songs = p_loc.size(0)\r\n",
    "    # Determinant of Covariance Matrix\r\n",
    "    norm_2 = torch.sum((p_loc - q_loc)*(p_loc - q_loc), dim=2)\r\n",
    "    print(norm_2.size())\r\n",
    "    # Dimension of Maltivariate Normal Distribution\r\n",
    "    trace_p_scale = torch.sum(p_scale, dim=2)\r\n",
    "    trace_q_scale = torch.sum(q_scale, dim=2)\r\n",
    "    trace = torch.sum(torch.sqrt(p_scale*q_scale), dim=2)\r\n",
    "    # KL-divergence\r\n",
    "    Wass = torch.sqrt(norm_2 + trace_p_scale + trace_q_scale - 2 * trace)\r\n",
    "    return Wass.sum() / (beats * songs)\r\n",
    "\r\n",
    "def multi_normal_prob(loc,scale,x):\r\n",
    "    # locは平均, scaleは共分散行列, xはサンプルとする。\r\n",
    "    pi_2_d = torch.tensor(np.sqrt((np.pi * 2) ** loc.size(-1)))\r\n",
    "    det = torch.sum(scale, dim=2)\r\n",
    "    # mom = torch.sqrt(det) * pi_2_d\r\n",
    "    exp_arg = -0.5 * torch.sum((x-loc) * (x-loc) / scale, dim=2)\r\n",
    "    return torch.exp(exp_arg)\r\n",
    "\r\n",
    "regularizer = D_Wass(pos_z_loc, pri_z_loc, pos_z_scale, pri_z_scale)\r\n",
    "print(regularizer)\r\n",
    "print(multi_normal_prob(pos_z_loc,pos_z_scale,pos_z)*(multi_normal_prob(pos_z_loc,pos_z_scale,pos_z)-multi_normal_prob(pri_z_loc,pri_z_scale,pri_z)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 20])\n",
      "tensor(0.1029, grad_fn=<DivBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for para in optimizer.param_groups[0]['params']:\r\n",
    "    if para.grad == None:\r\n",
    "        continue\r\n",
    "    print(any(torch.isnan(para.grad.reshape(-1))), end=\"\")\r\n",
    "    if any(torch.isnan(para.grad.reshape(-1))):\r\n",
    "        print(para.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalse"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(pos_z_loc.max())\r\n",
    "print(pos_z_loc.min())\r\n",
    "print(pos_z_scale.max())\r\n",
    "print(pos_z_scale.min())\r\n",
    "print(pri_z_loc.max())\r\n",
    "print(pri_z_loc.min())\r\n",
    "print(pri_z_scale.max())\r\n",
    "print(pri_z_scale.min())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.6706, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.4711, grad_fn=<MinBackward1>)\n",
      "tensor(0.0055, grad_fn=<MaxBackward1>)\n",
      "tensor(1.7351e-05, grad_fn=<MinBackward1>)\n",
      "tensor(0.6704, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.4622, grad_fn=<MinBackward1>)\n",
      "tensor(0.0055, grad_fn=<MaxBackward1>)\n",
      "tensor(1.8112e-05, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "source": [
    "optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "source": [
    "for para in optimizer.param_groups[0]['params']:\r\n",
    "    print(any(torch.isnan(para.reshape(-1))), end=\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FalseTrueTrueTrueTrueTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalseFalse"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "74e73a0e7102a893564b6115a2124e9976edb53d12febb5cf682a47c83cf5635"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
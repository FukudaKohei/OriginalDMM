{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import TransformedDistribution\n",
    "from pyro.distributions.transforms import affine_autoregressive\n",
    "\n",
    "import ot\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "source": [
    "# DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(8):\n",
    "        training_data_sequences[i][0][int(70-i*10)  ] = 1\n",
    "        training_data_sequences[i][1][int(70-i*10)+2] = 1\n",
    "        training_data_sequences[i][2][int(70-i*10)+4] = 1\n",
    "        training_data_sequences[i][3][int(70-i*10)+5] = 1\n",
    "        training_data_sequences[i][4][int(70-i*10)+7] = 1\n",
    "        training_data_sequences[i][5][int(70-i*10)+9] = 1\n",
    "        training_data_sequences[i][6][int(70-i*10)+11] = 1\n",
    "        training_data_sequences[i][7][int(70-i*10)+12] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "## ドドド、レレレ\n",
    "def superEasyTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(30+i*5)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "## ドドド、ドドド、ドドド\n",
    "def easiestTones():\n",
    "    training_seq_lengths = torch.tensor([8]*10)\n",
    "    training_data_sequences = torch.zeros(10,8,88)\n",
    "    for i in range(10):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(70)] = 1\n",
    "    return training_seq_lengths, training_data_sequences"
   ]
  },
  {
   "source": [
    "# WASSERSTEIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMD2(xT, mud_arr):\n",
    "    # print(\"DONE0\")\n",
    "    x_p = xT.detach().clone().numpy()\n",
    "    mud_p = mud_arr.detach().clone().numpy()\n",
    "    \n",
    "    n_points = xT.size()[0]\n",
    "    n_tones = xT.size()[1]\n",
    "    dim = xT.size()[2]\n",
    "    # print(\"DONE1\")\n",
    "    # x_p = xT.reshape((n_points, dim)).cpu().detach().numpy()\n",
    "    x_p = x_p.reshape((n_points, n_tones * dim))\n",
    "    # mud_p = mud_arr.reshape((n_points, dim)).cpu().detach().numpy()\n",
    "    mud_p = mud_p.reshape((n_points, n_tones * dim))\n",
    "    # print(x_p.shape)\n",
    "    # print(mud_p.shape)\n",
    "    # print(\"DONE2\")\n",
    "    M = ot.dist(x_p, mud_p)\n",
    "    M /= M.max()\n",
    "    a, b = np.ones((n_points,)) / n_points, np.ones((n_points,)) / n_points  # uniform distribution on samples\n",
    "    gamma = ot.emd(a, b, M)\n",
    "    # wdis = ot.emd2_1d(xT, mud_arr)\n",
    "    # print('Wasserstein distance:', wdis)\n",
    "    # print(\"DONE3\")\n",
    "\n",
    "    Tx = []\n",
    "    for i, xTi in enumerate(x_p):\n",
    "        ind = gamma[i,:].argmax()\n",
    "        Tx.append(mud_arr[ind])\n",
    "        # print(f'index {i}: ind {ind} mud_p[{ind}]={mud_p[ind]}') \n",
    "    # print(\"DONE4\")\n",
    "    # print(Tx[0])\n",
    "    # Tx = torch.from_numpy(np.array(Tx).reshape((n_points, 1, n_tones*dim)))\n",
    "    # Tx = torch.tensor(Tx,dtype=torch.float32)\n",
    "    # x = xT.reshape(n_points,1,n_tones*dim)\n",
    "    # Wasser = F.mse_loss(x, Tx)\n",
    "    Tx = torch.stack(Tx)\n",
    "    return torch.norm(Tx-xT, dim=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1., grad_fn=<SumBackward0>)\n0.003001689910888672\n"
     ]
    }
   ],
   "source": [
    "_, song_1 = easiestTones()\n",
    "_, song_2 = superEasyTones()\n",
    "_, song_2 = easiestTones()\n",
    "song_2.requires_grad=True\n",
    "# print(song_2[0][1][30])\n",
    "song_2[0][1][30] = 1.\n",
    "now = time.time()\n",
    "print(EMD2(song_1, song_2))\n",
    "print(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[3., 4.], [3., 4.]])\n",
    "b = torch.tensor([1])\n",
    "wass = torch.norm(a, dim=1)\n",
    "print(wass.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import ot\n",
    "\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly"
   ]
  },
  {
   "source": [
    "# Wassの計算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SIZE = torch.Size([3, 8, 88])\ntorch.Size([曲数, 曲の長さ, 鍵数])\n"
     ]
    }
   ],
   "source": [
    "#　曲数\n",
    "N = 3\n",
    "\n",
    "#ドレミ系\n",
    "def easyTones(N):\n",
    "    max = 70\n",
    "    interval = 10\n",
    "    training_seq_lengths = torch.tensor([8]*N)\n",
    "    training_data_sequences = torch.zeros(N,8,88)\n",
    "    for i in range(N):\n",
    "        training_data_sequences[i][0][int(max-i*interval)  ] = 1\n",
    "        training_data_sequences[i][1][int(max-i*interval)+2] = 1\n",
    "        training_data_sequences[i][2][int(max-i*interval)+4] = 1\n",
    "        training_data_sequences[i][3][int(max-i*interval)+5] = 1\n",
    "        training_data_sequences[i][4][int(max-i*interval)+7] = 1\n",
    "        training_data_sequences[i][5][int(max-i*interval)+9] = 1\n",
    "        training_data_sequences[i][6][int(max-i*interval)+11] = 1\n",
    "        training_data_sequences[i][7][int(max-i*interval)+12] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、レレレ\n",
    "def superEasyTones(N):\n",
    "    training_seq_lengths = torch.tensor([8]*N)\n",
    "    training_data_sequences = torch.zeros(N,8,88)\n",
    "    for i in range(N):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(30+i*5)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## ドドド、ドドド、ドドド\n",
    "def easiestTones(N):\n",
    "    training_seq_lengths = torch.tensor([8]*N)\n",
    "    training_data_sequences = torch.zeros(N,8,88)\n",
    "    for i in range(N):\n",
    "        for j in range(8):\n",
    "            training_data_sequences[i][j][int(70)] = 1\n",
    "    return training_seq_lengths, training_data_sequences\n",
    "\n",
    "## クラシック\n",
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "classic_mini_batch = data['train']['sequences'][:N,:8]\n",
    "\n",
    "## ドレミ系\n",
    "_,CDE_mini_batch = easyTones(N)\n",
    "\n",
    "## ドドド、レレレ、ミミミ系\n",
    "_,DDD_mini_batch = superEasyTones(N)\n",
    "\n",
    "## ドドドだけ\n",
    "_,CCC_mini_batch = easiestTones(N)\n",
    "\n",
    "if classic_mini_batch.size() == CDE_mini_batch.size() and \\\n",
    "   classic_mini_batch.size() == DDD_mini_batch.size() and \\\n",
    "   classic_mini_batch.size() == CCC_mini_batch.size():\n",
    "   print(\"SIZE =\", classic_mini_batch.size())\n",
    "   print(\"torch.Size([曲数, 曲の長さ, 鍵数])\")\n",
    "else :\n",
    "    assert(\"ERROR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMD(training_mini_batch, generated_mini_batch):\n",
    "    # データの確認\n",
    "    if training_mini_batch.size() != generated_mini_batch.size():\n",
    "        assert(\"ERROR at Wass\")\n",
    "\n",
    "    # numpy バージョンの生成\n",
    "    trn_np = training_mini_batch.detach().clone().numpy()\n",
    "    gnt_np = generated_mini_batch.detach().clone().numpy()\n",
    "    \n",
    "    # 曲数\n",
    "    n_songs = training_mini_batch.size()[0]\n",
    "    # 曲の長さ\n",
    "    n_tones = training_mini_batch.size()[1]\n",
    "    # 鍵数\n",
    "    dim = training_mini_batch.size()[2]\n",
    "    \n",
    "    trn_np = trn_np.reshape((n_songs, n_tones * dim))\n",
    "    gnt_np = gnt_np.reshape((n_songs, n_tones * dim))\n",
    "    \n",
    "    # ot の使用\n",
    "    M = ot.dist(trn_np, gnt_np)\n",
    "    M /= M.max() #　不要かも\n",
    "    a, b = np.ones((n_songs,)) / n_songs, np.ones((n_songs,)) / n_songs  # uniform distribution on samples\n",
    "    gamma = ot.emd(a, b, M)\n",
    "\n",
    "    # 近似計算の実行\n",
    "    Tx = []\n",
    "    for i in range(n_songs):\n",
    "        ind = gamma[i,:].argmax()\n",
    "        Tx.append(generated_mini_batch[ind])\n",
    "    Tx = torch.stack(Tx)\n",
    "    return torch.norm(Tx-training_mini_batch, dim=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.)\ntensor(61.8017)\ntensor(31.3026)\ntensor(16.9706)\n"
     ]
    }
   ],
   "source": [
    "print(EMD(classic_mini_batch,classic_mini_batch))\n",
    "print(EMD(classic_mini_batch,CCC_mini_batch))\n",
    "print(EMD(CDE_mini_batch,CCC_mini_batch))\n",
    "print(EMD(DDD_mini_batch,CCC_mini_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
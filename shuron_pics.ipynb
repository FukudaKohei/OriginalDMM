{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import TransformedDistribution\n",
    "from pyro.distributions.transforms import affine_autoregressive\n",
    "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceEnum_ELBO, TraceTMC_ELBO, config_enumerate\n",
    "from pyro.optim import ClippedAdam\n",
    "import ot\n",
    "import torch.nn.functional as F\n",
    "import mido\n",
    "import musics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    def __init__(self, input_dim, z_dim, emission_dim, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.use_cuda = use_cuda\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim)\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim)\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z_t):\n",
    "        h1 = self.relu(self.lin_z_to_hidden(z_t))\n",
    "        h2 = self.relu(self.lin_hidden_to_hidden(h1))\n",
    "        if self.input_dim == 1:\n",
    "            x = self.lin_hidden_to_input(h2)\n",
    "        else:\n",
    "            ps = torch.sigmoid(self.lin_hidden_to_input(h2))\n",
    "            if self.use_cuda: \n",
    "                eps = torch.rand(self.input_dim).cuda()\n",
    "            else : eps = torch.rand(self.input_dim)\n",
    "            appxm = torch.log(eps + 1e-20) - torch.log(1-eps + 1e-20) + torch.log(ps + 1e-20) - torch.log(1-ps + 1e-20)\n",
    "            x = torch.sigmoid(appxm)\n",
    "        return x\n",
    "\n",
    "class GatedTransition(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # initialize the six linear transformations used in the neural network\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim)\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        # modify the default initialization of lin_z_to_loc\n",
    "        # so that it's starts out as the identity function\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        # initialize the three non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1):\n",
    "        _gate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\n",
    "        gate = torch.sigmoid(self.lin_gate_hidden_to_z(_gate))\n",
    "        _proposed_mean = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\n",
    "        scale = self.softplus(self.lin_sig(self.relu(proposed_mean)))\n",
    "        return loc, scale\n",
    "\n",
    "class Combiner(nn.Module):\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        loc = self.lin_hidden_to_loc(h_combined)\n",
    "        scale = self.softplus(self.lin_hidden_to_scale(h_combined))\n",
    "        return loc, scale\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=88, z_dim=100,rnn_dim=60, num_layers=1, rnn_dropout_rate=0.1,num_iafs=0, iaf_dim=50, N_z0 = 10, use_cuda=False, rnn_check=False):\n",
    "        super().__init__()\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        rnn_dropout_rate = 0. if num_layers == 1 else rnn_dropout_rate\n",
    "        self.rnn = nn.RNN(input_size=input_dim, hidden_size=rnn_dim, nonlinearity='relu',\n",
    "                            batch_first=True, bidirectional=False, num_layers=num_layers,\n",
    "                            dropout=rnn_dropout_rate)\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.h_0 = nn.Parameter(torch.randn(1, 1, rnn_dim))\n",
    "        self.use_cuda = use_cuda\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.rnn_check = rnn_check\n",
    "\n",
    "    def forward(self, mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths, annealing_factor=1.0):\n",
    "        T_max = mini_batch.size(1)\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0), self.rnn.hidden_size).contiguous()\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        rnn_output = poly.pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "        z_container = []\n",
    "        z_loc_container = []\n",
    "        z_scale_container = []\n",
    "        for t in range(1,T_max+1):\n",
    "            z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "            if self.use_cuda:\n",
    "                eps = torch.randn(z_loc.size()).cuda()\n",
    "            else: eps = torch.randn(z_loc.size())\n",
    "            z_t = z_loc + z_scale * eps\n",
    "            z_prev = z_t\n",
    "            z_container.append(z_t)\n",
    "            z_loc_container.append(z_loc)\n",
    "            z_scale_container.append(z_scale)\n",
    "        \n",
    "        z_container = torch.stack(z_container)\n",
    "        z_loc_container = torch.stack(z_loc_container)\n",
    "        z_scale_container = torch.stack(z_scale_container)\n",
    "        return z_container.transpose(0,1), z_loc_container.transpose(0,1), z_scale_container.transpose(0,1)\n",
    "\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, z_dim=100, transition_dim=200,  N_z0 = 10, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward(self, length, N_generate):\n",
    "        T_max = length\n",
    "        z_prev = self.z_q_0.expand(N_generate, self.z_q_0.size(0))\n",
    "        z_container = []\n",
    "        z_loc_container = []\n",
    "        z_scale_container = []\n",
    "        for t in range(1,T_max+1):\n",
    "            z_loc, z_scale = self.trans(z_prev)\n",
    "            if self.use_cuda:\n",
    "                eps = torch.randn(z_loc.size()).cuda()\n",
    "            else: eps = torch.randn(z_loc.size())\n",
    "            z_t = z_loc + z_scale * eps\n",
    "            z_prev = z_t\n",
    "            z_container.append(z_t)\n",
    "            z_loc_container.append(z_loc)\n",
    "            z_scale_container.append(z_scale)\n",
    "        z_container = torch.stack(z_container)\n",
    "        z_loc_container = torch.stack(z_loc_container)\n",
    "        z_scale_container = torch.stack(z_scale_container)\n",
    "        return z_container.transpose(0,1), z_loc_container.transpose(0,1), z_scale_container.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = \"重要20220114_14_57\"\n",
    "now = \"20220116_11_55\"\n",
    "now = \"20220116_14_26\"\n",
    "now = \"20220116_17_30\"\n",
    "now = \"20220116_20_49\"\n",
    "# est_path = os.path.join(\"saveEstimate\", now)\n",
    "# os.makedirs(est_path, exist_ok=True)\n",
    "\n",
    "# get the name of dir of saveData\n",
    "data_path = os.path.join(\"saveData\", now)\n",
    "files = os.listdir(data_path)\n",
    "files_dir = [f for f in files if os.path.isdir(os.path.join(data_path, f))]\n",
    "files_dir.sort()\n",
    "\n",
    "N_songs = 10\n",
    "length = 4\n",
    "mini_batch_size = 20\n",
    "z_dim = 2 #100 #2\n",
    "rnn_dim = 30 #200 #30\n",
    "transition_dim = 30 #200 #30\n",
    "emission_dim = 30 #100 #30\n",
    "\n",
    "reconstructions = []\n",
    "generations = []\n",
    "trainings = []\n",
    "for i in range(len(files_dir)):\n",
    "    encoder = Encoder(input_dim=1, z_dim=z_dim, rnn_dim=rnn_dim, N_z0=N_songs)\n",
    "    prior = Prior(z_dim=z_dim, transition_dim=transition_dim,  N_z0=N_songs)\n",
    "    decoder = Emitter(input_dim=1, z_dim=z_dim, emission_dim=emission_dim)\n",
    "    # if files_dir[i] == \"Epoch2000\":\n",
    "    #     continue\n",
    "    DMM_dics = torch.load(os.path.join(data_path, files_dir[i],\"DMM_dic\"))\n",
    "    training_data_sequences = DMM_dics[\"mini_batch\"]\n",
    "    encoder.load_state_dict(DMM_dics[\"Encoder_dic\"]())\n",
    "    prior.load_state_dict(DMM_dics[\"Prior_dic\"]())\n",
    "    decoder.load_state_dict(DMM_dics[\"Emitter_dic\"]())\n",
    "\n",
    "    which_mini_batch = 0\n",
    "    training_seq_lengths = torch.tensor([length]*N_songs)\n",
    "    data_dim = training_data_sequences.size(-1)\n",
    "\n",
    "    N_train_data = len(training_seq_lengths)\n",
    "    N_train_time_slices = float(torch.sum(training_seq_lengths))\n",
    "    N_mini_batches = int(N_train_data / mini_batch_size +\n",
    "                    int(N_train_data % mini_batch_size > 0))\n",
    "    shuffled_indices = torch.randperm(N_train_data)\n",
    "    mini_batch_start = (which_mini_batch * mini_batch_size)\n",
    "    mini_batch_end = np.min([(which_mini_batch + 1) * mini_batch_size, N_train_data])\n",
    "    mini_batch_indices = shuffled_indices[mini_batch_start:mini_batch_end]\n",
    "\n",
    "    # grab a fully prepped mini-batch using the helper function in the data loader\n",
    "    mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "        = poly.get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                                training_seq_lengths)\n",
    "\n",
    "    pri_z, pri_z_loc, pri_z_scale = prior(length = mini_batch.size(1), N_generate= 1000)\n",
    "    pos_z,a,b = encoder(mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths)\n",
    "    reconed_x = decoder(pos_z)\n",
    "    reconstructions.append(reconed_x)\n",
    "    generations.append(decoder(pri_z))\n",
    "    trainings.append(mini_batch)\n",
    "    # entropy = 0\n",
    "    # entropy -= torch.sum(torch.log(multi_normal_prob(pri_z_loc, pri_z_scale, pri_z))) / args.N_generate\n",
    "    # entropy += 0.5 * pri_z.size(1) * pri_z.size(2) * torch.log(torch.tensor(2*math.pi))\n",
    "    # how_close = calc_how_close_to_mini_batch(decoder(pri_z), mini_batch)\n",
    "\n",
    "    # ppath = os.path.join(est_path, files_dir[i])\n",
    "    # os.makedirs(ppath, exist_ok=True)\n",
    "    # os.makedirs(os.path.join(ppath,\"Reconstruction\"), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(ppath,\"Generation\"), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(ppath,\"Training\"), exist_ok=True)\n",
    "    # for j in range(args.N_pics):\n",
    "    #     saveReconSinGraph(mini_batch[j], reconed_x[j], pri_z.size(1), os.path.join(ppath,\"Reconstruction\"), j, args.date)\n",
    "    # saveGeneSinGraph(decoder(pri_z)[:3], pri_z.size(1), os.path.join(ppath,\"Generation\"), j, args.date)\n",
    "    # saveTrainSinGraph(mini_batch[:5], pri_z.size(1), os.path.join(ppath,\"Training\"), 1, args.date)\n",
    "reconstructions = torch.stack(reconstructions)\n",
    "generations = torch.stack(generations)\n",
    "trainings = torch.stack(trainings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc av of gene\n",
    "def cal_av(gene):\n",
    "    N = gene.size(0)\n",
    "    return gene.sum(dim=0) / N\n",
    "\n",
    "# cal sigma of gene\n",
    "def cal_sg(gene):\n",
    "    N = gene.size(0)\n",
    "    av = cal_av(gene)\n",
    "    av = av.expand(N, gene.size(1), gene.size(2))\n",
    "    return ((gene-av)*(gene-av)).sum(dim=0) / N\n",
    "\n",
    "files_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 23\n",
    "gene_av = cal_av(generations[number])\n",
    "gene_sg = cal_sg(generations[number])\n",
    "training_av = torch.tensor([[0.0], [3.0], [6.0], [9.0]])\n",
    "training_sg = torch.tensor([[1.0], [1.0], [1.0], [1.0]])\n",
    "\n",
    "print(gene_av)\n",
    "print(gene_sg)\n",
    "# for dat in generations[number]:\n",
    "#     plt.plot(dat.detach().numpy())\n",
    "\n",
    "FS = 15\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "# plt.title(\"Sin Curves\")\n",
    "plt.xlabel(\"t\", fontsize=15)\n",
    "# plt.ylabel(\"y\", fontsize=FS)\n",
    "plt.rcParams[\"font.size\"] = FS\n",
    "training_color = \"black\"\n",
    "plt.errorbar([0,1,2,3], training_av.detach().numpy(), yerr = training_sg.detach().numpy(), capsize=5, fmt='o', markersize=7, ecolor='black', markeredgecolor = \"black\", color='w')\n",
    "plt.plot([0,1,2,3], training_av.detach().numpy(),color='black', label=\"Training Data\")\n",
    "gene_color = \"orange\"\n",
    "plt.errorbar([0,1,2,3], gene_av.detach().numpy(), yerr = gene_sg.detach().numpy(), capsize=5, fmt='o', markersize=7, ecolor=gene_color, markeredgecolor = gene_color, color=gene_color)\n",
    "plt.plot([0,1,2,3], gene_av.detach().numpy(),color=gene_color, label=\"Generated Data\")\n",
    "plt.xticks([0,1,2,3], [0,1,2,3], size=15)\n",
    "plt.yticks([0, 3, 6, 9], [0, 3, 6, 9],size=15)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMM_dics = torch.load(os.path.join(data_path, files_dir[i],\"DMM_dic\"))\n",
    "loss = torch.stack(DMM_dics[\"losses\"])\n",
    "recon_error = torch.stack(DMM_dics[\"recon_errors\"])\n",
    "\n",
    "FS = 15\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.xlim(0, 2300)\n",
    "# plt.ylabel(\"y\", fontsize=FS)\n",
    "plt.rcParams[\"font.size\"] = FS\n",
    "training_color = \"black\"\n",
    "plt.plot(loss.detach().numpy(),color='black', label=\"Loss\")\n",
    "gene_color = \"orange\"\n",
    "plt.plot(recon_error.detach().numpy(),color='red', label=\"Reconstruction Error\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74e73a0e7102a893564b6115a2124e9976edb53d12febb5cf682a47c83cf5635"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
